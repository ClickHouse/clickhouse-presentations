<!DOCTYPE html>
<html lang="en">
<head>
    <title>How to Speed Up LZ4 Decompression</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:image" content="pictures/preview.jpg">
    <meta property="og:title" content="How to Speed Up LZ4 Decompression">
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="pictures/preview.jpg">
    <link rel="stylesheet" href="shower/themes/clickhouse/styles/styles.css">

    <style>
        code { display: block; white-space: pre; background-color: #EEE; }
    </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>How to Speed Up LZ4 Decompression</h1>
    </header>
    <section class="slide" id="cover" style="background: #FFF url('pictures/title.png') no-repeat; background-size: 100%;">
        <h1 style="margin-top: 50px; margin-left: -40px; line-height: 150%">How to Speed Up LZ4 Decompression</h1>
    </section>


<section class="slide">
<pre style="margin-top: 50px; font-size: 32pt; line-height: 1.5em;">SELECT * FROM hits_100m
WHERE URL LIKE '%metrika%'
ORDER BY EventTime LIMIT 10</pre>
<p>0.772 sec.<br/>11.0 GiB/sec.<br/>125.98 million rows/sec.</p>
</section>

<section class="slide">
<img src="pictures/perf.png" width="100%" style="margin-top: 50px;" />
</section>

<section class="slide">
<h2>What is LZ4</h2>
<p>&mdash; data compression library;</p>
<p>&mdash; high performance;</p>
<p>&mdash; special case of LZ77 algorithm;</p>
<p>&mdash; not specialized for specific data types;</p>
<p>&mdash; exists since 2011;</p>
<p>&mdash; used in ClickHouse since 2011;</p>
<p>&mdash; author &mdash; Yann Collet;</p>
<p>&mdash; analogues: Snappy, QuickLZ, LZO, FastLZ, BriefLZ, LZF;</p>
</section>

<section class="slide">
<h2>Why LZ4 Specifically</h2>
<p>It's almost &laquo;Pareto-optimal&raquo;.</p>
<p>We compare algorithms by three parameters<br/>on all possible datasets:
<br/>&mdash; compression ratio;
<br/>&mdash; compression speed;
<br/>&mdash; decompression speed;
</p>
<p>An algorithm is called &laquo;Pareto-optimal&raquo; if there is no other algorithm that is better in at least one parameter and not worse in all others.</p>
</section>

<section class="slide">
<h2>There Are Slightly &laquo;Cooler&raquo; Options:</h2>
<p>Lizard (formerly LZ5): <a href="https://github.com/inikep/lizard/">https://github.com/inikep/lizard/</a></p>
<p>LZSSE: <a href="https://github.com/ConorStokes/LZSSE/">https://github.com/ConorStokes/LZSSE/</a></p>
<p>density: <a href="https://github.com/centaurean/density">https://github.com/centaurean/density</a></p>
<p>LZTURBO: <a href="https://sites.google.com/site/powturbo/">https://sites.google.com/site/powturbo/</a></p>
</section>

<section class="slide">
<h2>Why Is Decompression a Bottleneck?</h2>
<p>Typical decompression speed is several GB/sec on a single CPU core.</p>
<p>Decompression is done in multiple threads,<br/>which gives a speed of 10 GB/sec and more.</p>
<p>This is more than the speed of HDD and SSD arrays,<br/>so decompression shouldn't be a bottleneck?</p>
<p>But:</p>
<p>Compressed data is read from disk, which reduces IO.</p>
<p>Data is often in the page cache<br/>
&mdash; then the CPU will always be the bottleneck, not IO.</p>
</section>

<section class="slide">
<h2>Should We Compress Data at All?</h2>
<p>&mdash; yes.</p>
<p>If we don't &mdash; we'll hit IO or data volume limits.</p>
<p>Always compress data:<br/>
&mdash; when storing, even if you have an array of fast NVMe SSDs;<br/>
&mdash; when transmitting data over the network, even with 10 GBit without oversubscription;</p>
</section>

<section class="slide">
<h2>How LZ4 Works*</h2>
<p>A compressed file is a set of two types of commands,<br/>executing which results in data decompression:</p>
<p><b>Literals</b>: copy the next N bytes of compressed data as is.</p>
<p><b>Match</b>: copy N bytes at offset M,<br/>which were recently decompressed.</p>

<pre>Hello world Hello</pre>

<pre>literals 12 "Hello world " match 5 12</pre>

<p style="font-size: 12pt; color: #888;">* &mdash; except for small details; any LZ77 family algorithm;</p>
</section>

<section class="slide">
<h2>How to Compress Data</h2>
<p>&mdash; iterate through the data;</p>
<p>&mdash; hash the next 4 bytes;</p>
<p>&mdash; put the offset in a hash table;</p>
<p>&mdash; if these 4 bytes are already there - we found a match;</p>
<p>&mdash; look at the maximum match length;</p>
<p>&mdash; write the command "repeat data of such length at such offset" to the compressed file;</p>
</section>

<section class="slide">
<h2>How to Decompress Data</h2>
<code>
while (...)
{
    read(input_pos, literal_length, match_length);

    <b>copy</b>(output_pos, input_pos, literal_length);
    output_pos += literal_length;

    read(input_pos, match_offset);

    <b>copy</b>(output_pos, output_pos - match_offset,
        match_length);
    output_pos += match_length;
}</code>
</section>

<section class="slide">
<h2>How to Copy a Memory Block?</h2>
</section>

<section class="slide">
<h2 style="text-align: center; margin-top: 20%;">memcpy</h2>
</section>

<section class="slide">
<h2>&mdash; memcpy is slow*;</h2>
<h2 style="line-height: 1.5em;">&mdash; memcpy is not always<br/>correct to use;<h2>
<p style="font-size: 12pt; color: #888; margin-top: 100px;">* &mdash; in this usage scenario;</p>
</section>

<section class="slide">
<h2>Why Is memcpy Non-Optimal?</h2>

<p>1. Because memcpy is usually in the libc library, and the libc library is usually dynamically linked, and the call to memcpy will be indirect, through PLT.</p>
<p>2. Because the memcpy function with an unknown size argument at compile time is not inlined.</p>
<p>3. Because the memcpy function makes a lot of effort to correctly handle &laquo;tails&raquo; of memory chunks that are not multiples of the machine word or register size.</p>
</section>

<section class="slide">
<h2>We Can Write Extra Bytes</h2>

<p>We can always copy in chunks that are multiples of 8 (or 16, 32...) bytes.</p>
<p>This optimization is already present in the original LZ4 implementation.</p>

<code><span style="color: green;"><b>Hello</b></span> world <span style="color: gray;">...........</span>
^^^^^ - src
            ^^^^^ - dst
</code>
<code style="margin-top: 20px; margin-bottom: 20px;">Hello world <span style="color: green;"><b>Hello</b></span> <span style="color: red;">wo</span><span style="color: gray;">...</span>
^^^^^<span style="color: red">^^^</span> - src
            ^^^^^<span style="color: red">^^^</span> - dst
</code>
<p>(but we need to check for buffer overflow)</p>
</section>

<section class="slide">
<h2>We Can Write Extra Bytes</h2>
<code style="margin-top: -30px;">void copy8(UInt8 * dst, const UInt8 * src)
{
    <span style="color: #08F;">/// Here memcpy is not called (builtin).</span>
    memcpy(dst, src, 8);
}

void wildCopy8(
    UInt8 * dst, const UInt8 * src, UInt8 * dst_end)
{
    do
    {
        copy8(dst, src);
        dst += 8;
        src += 8;
    } while (dst &lt; dst_end);
}</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Need to Check for Buffer Overflow</h2>

    <blockquote>The last 5 bytes are always literals
    <br/>The last match must start at least 12 bytes before end of block.
    <br/>Consequently, a block with less than 13 bytes cannot be compressed.</blockquote>

<p><br/>&mdash; <a href="https://github.com/lz4/lz4/wiki/lz4_Block_format.md">https://github.com/lz4/lz4/wiki/lz4_Block_format.md</a>
</section>

<section class="slide">
<h2 style="font-size: 36pt;">Why Copy Exactly 8 Bytes?</h2>

<p>&mdash; why isn't the loop unrolled?</p>
<p>&mdash; why don't we use SSE or AVX registers?</p>
</section>

<section class="slide">
<code style="margin-top: 30px;">void copy16(UInt8 * dst, const UInt8 * src)
{
    _mm_storeu_si128(reinterpret_cast<__m128i *>(dst),
        _mm_loadu_si128(reinterpret_cast<const __m128i *>(src)));
}

void wildCopy16(
    UInt8 * dst, const UInt8 * src, UInt8 * dst_end)
{
    do
    {
        copy16(dst, src);
        dst += 16;
        src += 16;
    } while (dst &lt; dst_end);
}</code>
</section>

<section class="slide">
<h2 style="font-size: 36pt;">Why Copy Exactly 8 Bytes?</h2>

<p>&mdash; it's not obvious which is better;</p>
<p>&mdash; in the original LZ4 implementation
<br/>this is related to conditions in the compressed data format,
<br/>preventing memory overrun;</p>
</section>

<section class="slide">
<h2 style="font-size: 36pt;">Copying Match, Simple Case</h2>
<p>Copy 5 bytes at offset 12:</p>
<code><span style="color: green;"><b>Hello</b></span> world <span style="color: gray;">...........</span>
^^^^^ - src
            ^^^^^ - dst
</code>
<code style="margin-top: 20px;">Hello world <span style="color: green;"><b>Hello</b></span> <span style="color: gray;">wo...</span>
^^^^^ - src
            ^^^^^ - dst
</code>
</section>

<section class="slide">
<h2 style="font-size: 36pt;">Copying Match, Complex Case</h2>
<p>Copy 10 bytes at offset 3:</p>
<code><span style="color: green;"><b>abc</b></span><span style="color: gray;">.............</span>
^^^^^^^^^^ - src
   ^^^^^^^^^^ - dst
</code>
<code style="margin-top: 20px;">abc<span style="color: green;"><b>abcabcabca</b></span><span style="color: gray;">...</span>
^^^^^^^^^^ - src
   ^^^^^^^^^^ - dst
</code>
</section>

<section class="slide">
<h2 style="font-size: 36pt; line-height: 1.5em;">Need to Copy<br/>
As If We Were Doing It Byte by Byte</h2>

<code>op[0] = match[0];
op[1] = match[1];
op[2] = match[2];
op[3] = match[3];
...</code>
</section>

<section class="slide">
<code style="margin-top: 20px;"><span style="color: green;"><b>a</b></span>bc<span style="color: green;"><b>a</b></span><span style="color: gray;">............</span>
^ - src
   ^ - dst
</code>
<code style="margin-top: 20px;">a<span style="color: green;"><b>b</b></span>ca<span style="color: green;"><b>b</b></span><span style="color: gray;">...........</span>
 ^ - src
    ^ - dst
</code>
<code style="margin-top: 20px;">ab<span style="color: green;"><b>c</b></span>ab<span style="color: green;"><b>c</b></span><span style="color: gray;">..........</span>
  ^ - src
     ^ - dst
</code>
<code style="margin-top: 20px;">abc<span style="color: green;"><b>a</b></span>bc<span style="color: green;"><b>a</b></span><span style="color: gray;">.........</span>
   ^ - src
      ^ - dst
</code>
<code style="margin-top: 20px;">abca<span style="color: green;"><b>b</b></span>ca<span style="color: green;"><b>b</b></span><span style="color: gray;">........</span>
    ^ - src
       ^ - dst
</code>
</section>

<section class="slide">
<p>Copy the first 4 bytes byte by byte:</p>
<code style="margin-top: 10px; margin-bottom: 15px;">abc<span style="color: green;"><b>abca</b></span><span style="color: gray;">.........</span>
^^^^ - src
   ^^^^ - dst
</code>
<p>Now we can copy 4 bytes at once:</p>
<code style="margin-top: 10px; margin-bottom: 15px;">abcabca<span style="color: green;"><b>bcab</b></span><span style="color: gray;">.....</span>
 ^^^^ - src
       ^^^^ - dst
</code>
<p>Now we can copy 8 bytes at once:</p>
<code style="margin-top: 10px; margin-bottom: 15px;">abcabcabcab<span style="color: green;"><b>cabcabca</b></span><span style="color: gray;">.....</span>
  ^^^^^^^^ - src
           ^^^^^^^^ - dst
</code>
</section>

<section class="slide">
<h2>Surprisingly Confusing Code</h2>

<code style="margin-left: -20px; margin-right: -20px; line-height: 1.25em;">const unsigned dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4};
const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3};

const int dec64 = dec64table[offset];
op[0] = match[0];
op[1] = match[1];
op[2] = match[2];
op[3] = match[3];
match += dec32table[offset];
memcpy(op+4, match, 4);
match -= dec64;</code>
</section>

<section class="slide">
<code style="font-size: 15pt; margin-left: -50px; margin-right: -50px; line-height: 1.25em;">void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset)
{
    <span style="color: #08F;">/// 4 % n.</span>
    <span style="color: #08F;">/// Or if 4 % n is zero, we use n.</span>
    <span style="color: #08F;">/// It gives equivalent result, but is better CPU friendly.</span>
    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };

    <span style="color: #08F;">/// 8 % n - 4 % n</span>
    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };

    op[0] = match[0];
    op[1] = match[1];
    op[2] = match[2];
    op[3] = match[3];

    match += shift1[offset];
    memcpy(op + 4, match, 4);
    match += shift2[offset];
}</code>
</section>

<section class="slide">
<code style="font-size: 14pt; margin-left: -50px; margin-right: -50px; line-height: 1.1em;">void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset)
{
    <span style="color: #08F;">/// 4 % n.</span>
    static constexpr int shift1[]
        = { 0,  1,  2,  1,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4 };

    <span style="color: #08F;">/// 8 % n - 4 % n</span>
    static constexpr int shift2[]
        = { 0,  0,  0,  1,  0, -1, -2, -3, -4,  4,  4,  4,  4,  4,  4,  4 };

    <span style="color: #08F;">/// 16 % n - 8 % n</span>
    static constexpr int shift3[]
        = { 0,  0,  0, -1,  0, -2,  2,  1,  8, -1, -2, -3, -4, -5, -6, -7 };

    op[0] = match[0];
    op[1] = match[1];
    op[2] = match[2];
    op[3] = match[3];

    match += shift1[offset];
    memcpy(op + 4, match, 4);
    match += shift2[offset];
    memcpy(op + 8, match, 8);
    match += shift3[offset];
}</code>
</section>

<section class="slide">
<h2 style="font-size: 36pt; line-height: 1.5em;">Can We Implement &laquo;Clever&raquo; Copying More Optimally?</h2>

<p>Maybe there's a magic SIMD instruction<br/>
that will do everything we need at once?</p>
</section>

<section class="slide">
<h2>The pshufb Instruction</h2>

<p>&mdash; from the word shuffle;</p>
<p>&mdash; part of SSSE3 (three S's).</p>

<p>Takes two 16-byte registers:</p>
<p>&mdash; data to shuffle;</p>
<p>&mdash; &laquo;selector&raquo; &mdash; which byte to take for the i-th result byte.</p>
</section>

<section class="slide">
<h2>Example</h2>
<code style="line-height: 1.5em; margin-bottom: 20px;">xmm0: abc.............
xmm1: 0120120120120120

pshufb %xmm1, %xmm0

xmm0: abcabcabcabcabca
</code>
<p>Each result byte is filled with a byte we selected from the source data - exactly what we need!</p>
</section>

<section class="slide">
<code style="font-size: 12pt; margin-left: -50px; margin-right: -50px; line-height: 1em;">void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset)
{
    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =
    {
        <span style="color: #08F;">/* offset = 0, not used as mask, but for shift amount instead */</span>
        0,  1,  2,  1,  4,  1,  4,  2,  8,  7,  6,  5,  4,  3,  2,  1,
        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, <span style="color: #08F;">/* offset = 1 */</span>
        0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,
        0,  1,  2,  0,  1,  2,  0,  1,  2,  0,  1,  2,  0,  1,  2,  0,
        0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,
        0,  1,  2,  3,  4,  0,  1,  2,  3,  4,  0,  1,  2,  3,  4,  0,
        0,  1,  2,  3,  4,  5,  0,  1,  2,  3,  4,  5,  0,  1,  2,  3,
        0,  1,  2,  3,  4,  5,  6,  0,  1,  2,  3,  4,  5,  6,  0,  1,
        0,  1,  2,  3,  4,  5,  6,  7,  0,  1,  2,  3,  4,  5,  6,  7,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  0,  1,  2,  3,  4,  5,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  1,  2,  3,  4,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  0,  1,  2,  3,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,  0,  1,  2,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  1,
        0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,
    };

    _mm_storeu_si128(reinterpret_cast<__m128i *>(op),
        <b>_mm_shuffle_epi8</b>(
            _mm_loadu_si128(reinterpret_cast<const __m128i *>(match)),
            _mm_load_si128(reinterpret_cast<const __m128i *>(masks) + offset)));

    match += masks[offset];
}</code>
</section>

<section class="slide">
<h2>The pshufb Instruction</h2>
<p>Can also be used for 8 bytes:</p>
<p>&mdash; using MMX registers (bad);</p>
<p>&mdash; using 16-byte registers, just shuffling unnecessary bytes in the second half.</p>

<p>Analogous instructions:</p>
<p>&mdash; in AVX2: vpermb (incomplete);</p>
<p>&mdash; in AVX-512 VBMI - for 64 bytes at once;</p>
<p>&mdash; in ARM Neon: vtbl (incomplete).</p>
</section>

<section class="slide">
<h2 style="font-size: 32pt; line-height: 1.5em;">How to Avoid Checking<br/>Array Bounds?</h2>

<p>&mdash; simply ask the user<br/>to allocate more memory for buffers.</p>
<p>&mdash; but there may be performance degradation due to the allocator.</p>
</section>

<section class="slide">
<h2>Three Optimizations</h2>

<p>1. Copying 16 bytes instead of 8 bytes.</p>
<p>2. Using shuffle instruction for offset &lt; 16 case.</p>
<p>3. Removed one unnecessary if.</p>
</section>

<section class="slide">
<h2>Does This Give Speedup?</h2>

<p>Example 1:</p>
<p>Xeon E2650v2, Yandex.Browser data, AppVersion column.</p>
<p>reference: <b>1.67</b> GB/sec.
<br/>16 bytes, shuffle: <b>2.94</b> GB/sec (<b>76%</b> <span style="color: green;">faster</span>!).
</p>

<p>Example 2:</p>
<p>Xeon E2650v2, Yandex.Direct data, ShowsSumPosition column.</p>
<p>reference: <b>2.30</b> GB/sec.
<br/>16 bytes, shuffle: <b>1.91</b> GB/sec (<b>20%</b> <span style="color: red;">slower</span>).
</p>

</section>

<section class="slide">
<h2>Let's Make 4 Code Variants</h2>

<p>&mdash; operate with 8 or 16-byte chunks;</p>
<p>&mdash; use or don't use shuffle instruction.</p>

<code style="margin-top: 20px; line-height: 1.5em;">template &lt;size_t copy_amount, bool use_shuffle&gt;
void NO_INLINE decompressImpl(
     const char * const source,
     char * const dest,
     size_t dest_size)</code>
</section>

<section class="slide">
<code style="font-size: 16pt; margin-top: 50px; line-height: 1.5em;">sudo echo 'performance' |
    tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

kill -STOP $(pidof firefox) $(pidof chromium)</code>
</section>

<section class="slide">
<code style="font-size: 16pt; margin-top: 50px; line-height: 1.5em;">sudo kill -STOP \
    $(pidof python) \
    $(pidof perl) \
    $(pgrep -u skynet) \
    $(pidof cqudp-client)</code>
<p><br/>Otherwise the results will be unstable.</p>
</section>

<section class="slide">
<h2>How to Choose the Best Variant?</h2>

<p>&mdash; choose the one that's better on average,<br/>
on representative workload and current CPU models;</p>

<p>&mdash; manually write conditions<br/>
depending on compression ratio<br/>
and CPU model;</p>

<p>&mdash; test all variants on all available CPUs<br/>
or read reference manuals for instruction latency and throughput.</p>
</section>

<section class="slide">
<video style="width: 100%;"><source src="video/bandits.mp4" type="video/mp4"></video>
<p style="font-size: 12pt; color: #888;">Source: <a href="https://learnforeverlearn.com/bandits/">https://learnforeverlearn.com/bandits/</a></p>
</section>

<section class="slide">
<h2>Multi-Armed Bandits</h2>

<p>&mdash; randomly choose different variants;</p>
<p>&mdash; collect statistics for each;</p>
<p>&mdash; consider the time of each variant as a random variable;</p>
<p>&mdash; estimate the time distribution for each variant;</p>
</section>

<section class="slide">
<h2>Thompson Sampling</h2>

<p>&mdash; &laquo;simulate in our mind&raquo; a random variable for each variant;</p>
<p>&mdash; choose the one for which the simulated value turned out better.</p>
</section>

<section class="slide">
<h2>How to Estimate Distribution</h2>

<p>&mdash; Bayesian method;</p>
<p>&mdash; parametrically, something like Gamma distribution;</p>
<p>&mdash; parametrically, normal distribution;</p>
</section>

<section class="slide">
<h2 style="line-height: 1em;">Testing on Different CPUs</h2>

<p>Intel(R) Xeon(R) CPU<br/>
&mdash; E5-2650 v2 @ 2.60GHz<br/>
&mdash; E5-2660 v4 @ 2.00GHz<br/>
&mdash; E5-2660 0 @ 2.20GHz<br/>
&mdash; E5-2683 v4 @ 2.10GHz<br/>
&mdash; E5-2667 v2 @ 3.30GHz<br/>
&mdash; E312xx (Sandy Bridge)<br/>
&mdash; E5645 @ 2.40GHz<br/>
&mdash; E5530 @ 2.40GHz<br/>
&mdash; E5440 @ 2.83GHz</p>
<p>AMD EPYC 7351 16-Core Processor<br/>
AMD Opteron(TM) Processor 6274<br/>
AMD Opteron(tm) Processor 6380</p>
<p>Cavium ThunderX2</p>
</section>

<section class="slide">
<h2 style="font-size: 32pt;">Testing on Different CPUs and Datasets</h2>

<p>&mdash; we have 13 servers;</p>
<p>&mdash; each runs tests on 256 files;</p>
<p>&mdash; in 6 variants (reference, 0, 1, 2, 3, adaptive);</p>
<p>&mdash; and each test is run 10 times, alternating variants.</p>
<p>This gives 199,680 results that can be compared.</p>
</section>

<section class="slide">
<h2 style="font-size: 32pt;">Testing on Different CPUs and Datasets</h2>

<p>&mdash; on modern Intel, speedup is 13..17% on average;</p>
<p>&mdash; on AMD EPYC, speedup is 19.7% on average;</p>
<p>&mdash; on old Intel E5440 &mdash; &minus;1%;</p>
<p>&mdash; on Cavium &mdash; 3..4% (preliminary results);</p>
<p>&mdash; on all except E5440, multi-armed bandits on average<br/>are always better than any pre-selected variant.</p>
</section>

    <section class="slide">
        <h2>.</h2>
    </section>

    <section class="slide">
        <p style="margin-top: 50px;">Pull request: <a href="https://github.com/ClickHouse/ClickHouse/pull/1890">https://github.com/ClickHouse/ClickHouse/pull/1890</a><br/>(already merged)</p>
    </section>

    <section class="slide" style="padding: 20px;"><code style="font-size: 12pt; line-height: 1.5em;">┌─cpu───────────────────┬──ref─┬─adapt─┬──max─┬─best─┬─adapt_boost─┬─max_boost─┬─adapt_over_max─┐
│ E5-2667 v2 @ 3.30GHz  │ 2.81 │  3.19 │ 3.15 │    3 │        1.14 │      1.12 │           1.01 │
│ E5-2650 v2 @ 2.60GHz  │ 2.5  │  2.84 │ 2.81 │    3 │        1.14 │      1.12 │           1.01 │
│ E5-2683 v4 @ 2.10GHz  │ 2.26 │  2.63 │ 2.59 │    3 │        1.16 │      1.15 │           1.02 │
│ E5-2660 v4 @ 2.00GHz  │ 2.15 │  2.49 │ 2.46 │    3 │        1.16 │      1.14 │           1.01 │
│ AMD EPYC 7351         │ 2.03 │  2.44 │ 2.35 │    3 │        1.2  │      1.16 │           1.04 │
│ E5-2660 0 @ 2.20GHz   │ 2.13 │  2.39 │ 2.37 │    3 │        1.12 │      1.11 │           1.01 │
│ E312xx (Sandy Bridge) │ 1.97 │  2.2  │ 2.18 │    3 │        1.12 │      1.11 │           1.01 │
│ E5530 @ 2.40GHz       │ 1.65 │  1.93 │ 1.94 │    3 │        1.17 │      1.18 │           0.99 │
│ E5645 @ 2.40GHz       │ 1.65 │  1.92 │ 1.94 │    3 │        1.16 │      1.18 │           0.99 │
│ AMD Opteron 6380      │ 1.47 │  1.58 │ 1.56 │    1 │        1.07 │      1.06 │           1.01 │
│ AMD Opteron 6274      │ 1.15 │  1.35 │ 1.35 │    1 │        1.17 │      1.17 │              1 │
│ E5440 @ 2.83GHz       │ 1.35 │  1.33 │ 1.42 │    1 │        0.99 │      1.05 │           0.94 │
│ Cavium ThunderX2      │ 0.84 │  0.87 │ 0.87 │    0 │        1.04 │      1.04 │              1 │
└───────────────────────┴──────┴───────┴──────┴──────┴─────────────┴───────────┴────────────────┘</code></section>

    <div class="progress"></div>
    <script src="shower/shower.js"></script>

    <!--Video plugin-->
    <link rel="stylesheet" href="shower/shower-video.css">
    <script src="shower/shower-video.js"></script>
    <!--/Video plugin-->
<footer class="badge">
    <a href="https://presentations.clickhouse.com/">ClickHouse Theater</a>
</footer>
</body>
</html>
