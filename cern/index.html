<!DOCTYPE html>
<html lang="en">
<head>
    <title>ClickHouse &mdash; realtime analytical DBMS</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="shower/themes/ribbon/styles/screen-16x10.css">
</head>
<body class="shower list">
    <header class="caption">
        <h1>ClickHouse &mdash; realtime analytical DBMS</h1>
    </header>

    <section class="slide" id="cover">
        <h1 style="margin-top: 200px">ClickHouse</h1>
        <p>&mdash; open-source realtime analytical DBMS</p>
    </section>

    <section class="slide">
        <h2>Introduction</h2>
    </section>

    <section class="slide">
        <h2>About me</h2>
        <p>Alexey, developer of ClickHouse.</p>
        <p>I work on data processing engine of Yandex.Metrica since 2008.</p>
    </section>

    <section class="slide" style="background: url('pictures/yandex_office.jpg') no-repeat center center; background-size: 100% 100%;">
        <h2><span style="padding: 10px; background: rgba(255, 255, 255, 0.75);">About Yandex</span></h2>
        <p style="margin-top: 200px;"><span style="padding: 10px; line-height: 1.8; background: rgba(255, 255, 255, 0.75);">Yandex is one of the largest internet companies in Europe</span><br /><span style="padding: 10px; line-height: 1.8; background: rgba(255, 255, 255, 0.75);">operating Russia’s most popular search engine.</span></p>
    </section>

    <section class="slide">
        <h2>About Yandex.Metrica</h2>
        <p>Yandex.Metrica (https://metrica.yandex.com/) is a service for web analytics.</p>
        <p>Largest in Russia, second largest in the world (just after Google Analytics).</p>
        <p><img src="pictures/metrika_market_share.png"/></p>
        <p>We are processing about ~25 billions of events (page views, conversions, etc).</p>
        <p>We must generate and show reports in realtime.</p>
    </section>

    <section class="slide">
        <img src="pictures/metrika2.png" style="height:100%"/>
    </section>

    <section class="slide">
        <h2>History</h2>
    </section>

    <section class="slide">
        <h2>How to store data?</h2>
        <p>Big data processing is not a problem.</p>
        <p>The challenge is how to store data in that way to allow both:</p>
        <p>- efficient ingestion of click stream in realtime;</p>
        <p>- efficient generation of reports;</p>
        <p>&nbsp;</p>
        <p>Let review our historical solutions first...</p>
    </section>

    <section class="slide">
        <h2>MySQL (MyISAM) 2008-2011</h2>
        <p>We have had about 50 predefined report types.</p>
        <p>We create a table for each of them.</p>
        <p>Each table has primary key in form of:</p>
        <p>&nbsp;&nbsp;&nbsp;&nbsp;site_id, date, <i>key</i> -> aggregated statistics.</p>
        <p>The data was inserted in mini-batches of aggregated deltas,<br/>using ON DUPLICATE KEY UPDATE.</p>
        <p>&nbsp;</p>
        <p>... but this just don't work.</p>
    </section>

    <section class="slide">
        <h2>Data locality on disk (artistic view)</h2>
        <p>The main concern is <b>data locality</b>.</p>
        <img src="pictures/data_locality.png" style="width:100%"/>
    </section>

    <section class="slide">
        <h2>MySQL (MyISAM) 2008-2011</h2>
        <p>We use HDD (rotational drives).<br/>We cannot afford petabytes of SSDs.</p>
        <p>Each seek is ~12 ms of latency,<br/> usually no more than 1000 random reads/second in RAID array.</p>

        <p>Time to read data from disk array is dependent on:<br />- number of seeks;<br />- total amount of data;</p>

        <p>Example: read 100&nbsp;000 rows, randomly scattered on disk:<br />- at least 100 seconds in worst case.<br />User won't wait hundred seconds for the report.</p>

        <p>The only way to read data from disk array in appropriate amount of time is to minimize number of seek by maintaining data locality.</p>
    </section>

    <section class="slide">
        <h2>MySQL (MyISAM) 2008-2011</h2>
        <p>Fundamental problem:</p>

        <p>Data is <b>inserted</b> almost in time order:
        <br />- each second we have new portion data for this second;
        <br />- but data for different web sites are comes in random order in a stream;</p>

        <p>Data is <b>selected</b> by ranges for specified web site and date period:
        <br />- in ranges of completely different order;</p>
    </section>

    <section class="slide">
        <h2>MySQL (MyISAM) 2008-2011</h2>
        <p>MyISAM stores data in MYD and MYI files.<br/>MYD contains data almost in order of insertion.<br/>MYI contains B-tree index that maps a key to offset in MYD file.</p>
        <p>Insertion of data is almost fine.<br />But selecting of data by range of primary key was non-practical.</p>
        <p>Nevertheless, we made it work by:</p>
        <p>
        - tricky partitioning;<br/>
        - organizing data in few generations with different partitioning scheme;<br/>
        - moving data between tables by scheduled scripts;<br/>
        - report generation becomes ugly UNION ALL queries.</p>
    </section>

    <section class="slide">
        <h2>Aggregated vs. raw data</h2>
        <p>Users are not satisfied with 50 predefined reports.</p>
        <p>Everyone wants deep ad-hoc analytics with custom reports<br/>&mdash; to slice and dice data by any dimension.</p>
        <p>This is only possible with non-aggregated data.</p>
    </section>

    <section class="slide">
        <h2>The report builder, 2010</h2>
        <p>We had quickly made a prototype of so-called "report&nbsp;builder".</p>
        <p>This was 2010 year. It was just simple specialized column-oriented data structure.</p>
        <p>It worked fine and we got understanding, what the right direction to go.</p>
        <p>We need good column-oriented DBMS.</p>
    </section>

    <section class="slide">
        <h2>Why column-oriented?</h2>
        <p>This is how "traditional" row-oriented databases work:</p>
        <p><img src="pictures/row_oriented.gif"/></p>
    </section>

    <section class="slide">
        <h2>Why column-oriented?</h2>
        <p>And this is how column-oriented databases work:</p>
        <p><img src="pictures/column_oriented.gif"/></p>
    </section>

    <section class="slide">
        <h2>Why column-oriented?</h2>
        <p>Hypothesis:</p>
        <p>If we have good enough column-oriented DBMS,<br/>we could store all our data in non-aggregated form<br/>(raw pageviews and sessions) and generate all the reports on the fly,<br />to allow infinite customization.</p>
        <p>To check this hypothesis, we started to evaluate existing solutions.</p>
        <p>MonetDB, InfiniDB, Vertica, Infobright and so on...</p>
        <p>No appropriate solutions were exist in 2010.</p>
    </section>

    <section class="slide">
        <h2>ClickHouse</h2>
        <p>As an experimental project, we started to develop<br />our own column-oriented DBMS: ClickHouse.</p>
        <p>In 2012 it was in production state.</p>
        <p>In 2014 we re-lauched Yandex.Metrica as Metrica 2.</p>
        <p>All data is stored in ClickHouse and in non-aggregated form<br />and every report is generated on the fly.</p>
        <p>In Metrika 2 the user could create it's own report with<br />
        - custom dimensions, metrics, filters, user-centric segmentation...<br/>
        - and to dig through data to the detail of individual visitors.</p>
    </section>
    
    <section class="slide">
        <h2>ClickHouse</h2>
        <p>The main target for ClickHouse is query execution speed.</p>
        <p>In Yandex.Metrika, users could analyze data for their web sites of any volume.</p>
        <p>Biggest classifieds and e-commerce sites with hundreds millions PV/day are using Yandex.Metrika (e.g. ru.aliexpress.com).</p>
        <p>In contrast to GA*, in Yandex.Metrika, you could get data reports for large web sites without sampling.</p>
        <p>As data is processed on the fly, ClickHouse must be able to crunch all that pageviews in sub second time.</p>
        <p style="font-size:60%; margin-top:2em">* in Google Analytics you could get reports without sampling only in "premium" version.</p>
    </section>

    <section class="slide">
        <h2>The main cluster of Yandex.Metrica</h2>
        <ul style="font-size:30px;">
            <li>22 trillions of rows (as of May 2017)</li>
            <li>472 servers</li>
            <li>total throughput of query processing is up to two terabytes per second</li>
        </ul>
        <p style="font-size:60%; margin-top:2em">* If you want to try ClickHouse, one server or VM is enough.</p>
    </section>

    <section class="slide">
        <h2>ClickHouse</h2>
        <ul>
            <li>column-oriented</li>
            <li>distributed (including cross-DC replication)</li>
            <li>linearly scalable</li>
            <li>fault-tolerant</li>
            <li>data ingestion in realtime</li>
            <li>realtime (sub-second) queries</li>
            <li>support of SQL dialect + extensions<br/>(arrays, nested data types, domain-specific functions, approximate query execution)</li>
        </ul>
    </section>
    
    <section class="slide">
        <h2>When to use ClickHouse</h2>
        <p>For well structured, clean, immutable events.</p>
        <p>&nbsp;</p>
        <p>Click stream. Web analytics. Adv. networks. RTB. E-commerce.</p>
        <p>Analytics for online games. <span style="background-color: yellow;">Sensor and monitoring data</span>. Telecom&nbsp;data.</p>
        <p><span style="background-color: yellow;">Structured logs</span>.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 40px;">When <span style="color:red;">not</span> to use ClickHouse</h2>
        <p><span style="font-size: 30px;color: #888;">OLTP</span><br/>ClickHouse doesn't have UPDATE statement and full-featured transactions.</p>
        <p><span style="font-size: 30px;color: #888;">Key-Value</span><br/>If you want high load of small single-row queries, please use another system.</p>
        <p><span style="font-size: 30px;color: #888;">Blob-store, document oriented</span><br/>ClickHouse is intended for vast amount of fine-grained data.</p>
        <p><span style="font-size: 30px;color: #888;">Over-normalized data</span><br/>Better to make up single wide fact table with pre-joined dimensions.</p>
    </section>
    
    
    <section class="slide">
        <h2>Open-source (since June 2016)</h2>
        <p>We think ClickHouse is too good to be used solely by Yandex.</p>
        <p>We made it open-source. License: Apache 2.0.</p>
        <p>https://github.com/ClickHouse/ClickHouse/</p>
    </section>

    <section class="slide">
        <h2>Open-source</h2>
        <p>More than 100 companies are already using ClickHouse.</p>
        <p>In Russia: Mail.ru, Kaspersky, Kontur...</p>
        <p>In Europe, USA, China: CloudFlare, Wikimedia Foundation...</p>
    </section>
    
    <section class="slide">
        <h2>CloudFlare</h2>
        <p>How do we analyze over O(100B) DNS requests daily.</p>
        <p>"ClickHouse enables us and our customers to explore the the dataset in real time to get operational insights. Due to many of the optimizations built into ClickHouse we are able to store the data for a long time allowing us to look events is perspective and at historical trends."</p>
    </section>

    <section class="slide">
        <h2>Wikimedia.org</h2>
        <p>"clickhouse is a columnar datastore that we are using as an aid to run complex SQL queries on the edit data "lake" that we have as a result of the edit reconstruction project. It is similar to Druid but faster for complex queries."</p>
    </section>
    
    <section class="slide">
        <h2>SMI2 (news aggregator)</h2>
        <p>Throwed off InfiniDB, Cassandra and Druid<br/>just after public release of ClickHouse.</p>
    </section>
    
    <section class="slide">
        <h2>Rakam.io Analytics Platform</h2>
        <p>"When we evaluated ClickHouse the results were great compared to Prestodb. Even though the columnar storage optimizations for ORC and Clickhouse is quite similar, Clickhouse uses CPU and Memory resources more efficiently."</p>
    </section>
        
    <section class="slide">
        <h2 style="font-size: 30pt;">Unusual applications of ClickHouse</h2>

        <p>Bioinformatics - evolutionary genetics:
        <br/><a href="https://github.com/msestak/FindOrigin">https://github.com/msestak/FindOrigin</a></p>

        <p>"We are exploring evolution of novel genes in genomes because if seems that genomes are far from being static as previously believed and what actually happens is that new genes are constantly being added and old genes are lost."</p>
        
        <p>Search engine and analytics for Bitcoin transactions:
        <br/><a href="https://blockchair.com/">https://blockchair.com/</a></p>

        <p>"We have quite large tables on just single server and everything works really fast &mdash with any filters and sorting everything is processed just instantly."</p>
    </section>

    <section class="slide">
        <h2>ClickHouse and CERN</h2>
        <p>ClickHouse was already used in CERN: in LHCb experiment back in 2012.</p>
        <p>Back then ClickHouse was proprietary system, not available to general public.</p>
        <p>&nbsp;</p>
        <p>Now ClickHouse is mature open-source product.</p>
        <p>What a great time to live!</p>
    </section>
    
    <section class="slide">
        <h2>ClickHouse and CERN</h2>
        <p>Possible usages:</p>
        <p>- storage and fast analytics for non-aggregated events;</p>
        <p>- telemetry, sensor data;</p>
        <p>- analytics on experiments metadata.</p>
        <p>Possible drawbacks:</p>
        <p>- no integration with Hadoop.</p>
        <p>- don't use for large BLOBs (better to store them out of DB).</p>
    </section>
    
    
    <section class="slide">
        <h2>Performance</h2>
    </section>

    <section class="slide">
        <h2>ClickHouse vs. Spark</h2>
        <p>https://www.percona.com/blog/2017/02/13/clickhouse-new-opensource-columnar-database/</p>
        <img src="pictures/spark.png" style="height:60%"/>
    </section>

    <section class="slide">
        <h2>ClickHouse vs. PrestoDB</h2>
        <p>Ömer Osman Koçak:<br /><br />
        &laquo;When we evaluated ClickHouse the results were great compared to Prestodb. Even though the columnar storage optimizations for ORC and Clickhouse is quite similar, Clickhouse uses CPU and Memory resources more efficiently (Presto also uses vectorized execution but cannot take advantage of hardware level optimizations such as SIMD instruction sets because it's written in Java so that's fair) so we also wanted to add support for Clickhouse for our open-source analytics platform Rakam (https://github.com/rakam-io/rakam)&raquo;</p>
    </section>
    
    <section class="slide">
        <h2>ClickHouse vs. Vertica</h2>
        <p>Timur Shenkao:<br /><br />&laquo;ClickHouse is extremely fast at simple SELECTs without joins, much faster than Vertica&raquo;.</p>
    </section>
    
    <section class="slide">
        <h2>ClickHouse vs. InfiniDB</h2>
        <p>&laquo;结论：clickhouse速度更快！&raquo;</p>
        <p>&laquo;In conclusion, ClickHouse is faster!&raquo;</p>
        <p><a href="http://verynull.com/2016/08/22/infinidb与clickhouse对比/">http://verynull.com/2016/08/22/infinidb与clickhouse对比/</a></p>
        <p><img src="pictures/infinidb_cn.png" style="width:100%"/></p>
    </section>

    <section class="slide">
        <h2>Why ClickHouse is so fast?</h2>
        <p>&nbsp;</p>
        <p style="font-size: 40px;">&mdash; we just cannot make it slower.</p>
        <p style="font-size: 40px;">Yandex.Metrica must work.</p>
    </section>

    <section class="slide">
        <h2>Why ClickHouse is so fast?</h2>
        <p><b>Algorithmic optimizations.</b></p>
        <p>MergeTree, locality of data on disk<br/>— fast range queries.</p>
        <p>Example: uniqCombined function is a combination of three different data structures, used for different ranges of cardinalities.</p>
        <p><b>Low-level optimizations.</b></p>
        <p>Example: vectorized query execution.</p>
        <p><b>Specialization and attention to detail.</b></p>
        <p>Example: we have 17 different algorithms for GROUP BY. Best one is selected for your query.</p>
    </section>
    
    <section class="slide">
        <h2>Interfaces</h2>
    </section>
    
    <section class="slide">
        <h2>How to connect to ClickHouse</h2>
        <p style="font-size: 30px;"><span>HTTP REST</span></p>
        <p style="font-size: 30px;"><span>clickhouse-client</span></p>
        <p style="font-size: 30px;"><span>JDBC (production), ODBC (beta)</span></p>
        <p>&nbsp;</p>
        <p style="font-size: 30px;"><span>Python, PHP, Perl, Go,<br/>Node.js, Ruby, C++, .NET, Scala, R, Julia, Rust</span></p>
    </section>
    
    <section class="slide">
        <h2 style="font-size: 40px;">Integrations with data visualization tools</h2>
        <p style="font-size: 30px;">Tabix (tabix.io) &mdash; specifically developed for ClickHouse.</p>
        <p style="font-size: 30px;"><img style="float: left; padding-right: 20px;" src="pictures/tabix.gif" width="300" />And also:<br/><br/>Grafana, Redash, Apache Zeppelin,<br/>Superset, Power&nbsp;BI&hellip;</p>
    </section>
    
    
    <section class="slide">
        <h2><span>Community</span></h2>
        <p><span>Web site: <a href="https://clickhouse.com/">https://clickhouse.com/</a></span></p>
        <p><span>Google groups: <a href="https://groups.google.com/forum/#!forum/clickhouse">https://groups.google.com/forum/#!forum/clickhouse</a></span></p>
        <p><span>Maillist: clickhouse-feedback@yandex-team.com</span></p>
        <p><span>Telegram channel: <a href="https://telegram.me/clickhouse_en">https://telegram.me/clickhouse_en</a> and <a href="https://telegram.me/clickhouse_ru">https://telegram.me/clickhouse_ru</a> (now with 701 members)</span></p>
        <p><span>GitHub: <a href="https://github.com/ClickHouse/ClickHouse/">https://github.com/ClickHouse/ClickHouse/</a></span></p>
        <p>&nbsp;</p>
        <p><span>+ meetups.<br/>Moscow, Saint-Petersburg, Novosibirsk, Ekaterinburg, San-Francisco...<br/>
        Upcoming: Minsk. </span></p>
    </section>

    <section class="slide">
        <h2>&nbsp;</h2>
        <p style="font-size: 40px;">Thank you. Questions.</p>
    </section>

    
    <section class="slide">
        <h2>Bonus</h2>
    </section>

    <section class="slide">
        <h2 style="font-size: 40px;">ClickHouse vs. typical row-oriented DBMS</h2>
        <p>Itai Shirav:<br /><br />&laquo;I haven't made a rigorous comparison, but I did convert a time-series table with 9 million rows from Postgres to ClickHouse.</p>
        <p>Under ClickHouse queries run about 100 times faster, and the table takes 20 times less disk space. Which is pretty amazing if you ask me&raquo;.</p>
    </section>

    
    <section class="slide">
        <h2>InfluxDB</h2>
        <p>- no cluster in free version;</p>
        <p>- not capable for complex analytical queries;</p>
        <p>- slow ingestion performance;</p>
        <p>- many complaints about memory usage, startup time, consistency issues.</p>
    </section>
    
    <section class="slide">
        <h2>Elasticsearch</h2>
        <p>- fine if all indices fit in RAM;</p>
        <p>- high disk usage for data and indices;</p>
        <p>- almost not possible to use after some data volume threshold;</p>
        <p>- slow scans.</p>
    </section>
    
    <section class="slide">
        <h2>Spark SQL</h2>
        <p>- Spark is fine as a platform for data transformations;</p>
        <p>- not possible to ingest data in realtime while maintaining fast range scans - need to apply tricky partitioning and manual merging;</p>
        <p>- scans are relatively fast, though slower than ClickHouse;</p>
    </section>
    
    <section class="slide">
        <h2>Cassandra</h2>
        <p>- good for semistructured data;</p>
        <p>- slow scans, no complex analytical queries;</p>
    </section>
    
    <section class="slide">
        <h2>Kudu</h2>
        <p>- lambda architecture - complicated data model;</p>
    </section>
    

    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>
</body>
</html>
