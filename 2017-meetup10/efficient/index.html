<!DOCTYPE html>
<html lang="en">
<head>
    <title>Effective Use of ClickHouse</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:image" content="pictures/preview.jpg">
    <meta property="og:title" content="Effective Use of ClickHouse">
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="pictures/preview.jpg">
    <link rel="stylesheet" href="https://presentations.clickhouse.com/shower/themes/clickhouse/styles/styles.css">
    <style>
        pre { line-height: 1 }
    </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>Effective Use of ClickHouse</h1>
    </header>

    <section class="slide" id="cover">
        <h1 style="margin-top: 200px; font-size: 32pt;">Effective Use of<br/>ClickHouse</h1>
    </section>

    <section class="slide">
        <h2>About Me</h2>
        <p>Alexey, ClickHouse developer.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 28pt;">How to Misuse ClickHouse</h2>
        <p>Common mistakes we've encountered in practice.</p>
        <ul>
            <li>which scenario is suboptimal for ClickHouse;</li>
            <li>what architectural reasons lead to this suboptimality;</li>
            <li>and what best practices exist to avoid suboptimalities.</li>
        </ul>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">1. Too Frequent Inserts with Small Batch Size</h2>
        <p>Example:
        <br/>
        <br/>Table hits: 105 columns,
        <br/>row size in uncompressed binary format &mdash; 718 bytes.</p>
        <p>
            Batch size 1000000 rows:<br/>
            <br/>
            Insert into MergeTree table<br/>
            &mdash; <b>506,650</b> rows per second;<br/><br/>
            Insert into ReplicatedMergeTree with two replicas<br/>
            &mdash; <b>393,940</b> rows per second;<br/><br/>
            Insert into ReplicatedMergeTree<br/>
            with two replicas and insert_quorum = 2
            <br/>&mdash; <b>259,660</b> rows per second;<br/>
        </p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">1. Too Frequent Inserts with Small Batch Size</h2>
        <p>Example:
        <br/>
        <br/>Table hits: 105 columns,
        <br/>row size in uncompressed binary format &mdash; 718 bytes.</p>
        <p>
            Batch size &mdash; one row:<br/>
            <br/>
            Insert into MergeTree table<br/>
            &mdash; <b>59</b> rows per second;<br/><br/>
            Insert into ReplicatedMergeTree with two replicas<br/>
            &mdash; <b>6</b> rows per second;<br/><br/>
            Insert into ReplicatedMergeTree<br/>
            with two replicas and insert_quorum = 2
            <br/>&mdash; <b>2</b> rows per second;<br/>
        </p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">1. Too Frequent Inserts with Small Batch Size</h2>
        <p>&mdash; 10,000 .. 100,000 times slower.</p>
        <p><br/>Why does this happen?</p>
        <p>This is a ClickHouse limitation.</p>
        <p>MergeTree tables don't contain log and memtable.</p>
        <p>Data is immediately written to the file system,<br/>laid out by columns.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>
        <p>Method 1.</p><p>Use a distributed queue (Kafka).</p>
        <p>Pull data from the queue in batches once per second<br/>and write to ClickHouse.</p>

        <p><br/>Disadvantages:</p>
        <p>&mdash; cumbersome construction;</p>
        <p>&mdash; another complex distributed system.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>
        <p>Method 2.</p><p>Write logs to a file.</p>
        <p>Once per second, rename the file and open a new one.</p>
        <p>A separate process takes the oldest file and inserts it into ClickHouse.</p>

        <p><br/>Disadvantages:</p>
        <p>&mdash; possibility of data loss on hardware failure.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>
        <p>Method 3.</p><p>Server process accumulates a batch of logs in an internal buffer.</p>
        <p>Periodically, the accumulated buffer swaps with an empty one<br/>
        and a separate thread writes the accumulated data to ClickHouse.</p>

        <p><br/>Disadvantages:</p>
        <p>&mdash; data loss on kill -9 of the process;</p>
        <p>&mdash; data loss or OOM when unable to write to ClickHouse;</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>
        <p>Method 4.</p><p>Server process keeps a connection to ClickHouse open,<br/>
        in which an INSERT query is made and rows are sent one by one <br/>
        or in small batches with Transfer-Encoding: chunked.</p>

        <p>Periodically, the data stream ends<br/>and a new INSERT query is executed.</p>
        <p>In this case, ClickHouse will buffer the data<br/> on its side itself.</p>

        <p>Disadvantages:</p>
        <p>&mdash; data loss on kill -9 of the process;</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>
        <p>Method 5.</p>
        <p>https://github.com/nikepan/clickhouse-bulk</p>

        <p>&mdash; intermediate server for grouping INSERTs into batches;</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>
        <p>Method 6.</p><p>Buffer tables.</p>
        <p><br/>Advantages:</p>
        <p>&mdash; very easy to start using;</p>
        <p><br/>Disadvantages:</p>
        <p>&mdash; doesn't fully solve the problem, batches still needed;</p>
        <p>&mdash; adds other problems (no log, possible data loss).</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">Bonus</h2>
        <p>Support for importing from Kafka directly inside ClickHouse.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">More Pitfalls</h2>
        <p>&mdash; inserting data in VALUES format with computed expressions;</p>
        <p>&mdash; inserting data belonging to a large<br/>number of partitions in each batch.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 24pt;">2. String Typing</h2>
        <p>Example:</p>
        <p>Country String,
        <br/>City String,
        <br/>Browser String,
        <br/>IPAddress String,
        <br/>...
        </p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How Bad Is It?</h2>
        <p>Strings compress almost as well as numeric identifiers.</p>
        <p>There's almost no difference in disk and IO.<br/>
        But when processing a query, the CPU difference is at least several times.<br/>
        Example:</p>
        <p>SELECT uniqExact(IPAddress) FROM ip_address_num<br/>
        &mdash; <b>0.073</b> sec, <b>137.79</b> million rows/s.</p>

        <p>SELECT uniqExact(IPAddress) FROM ip_address_string<br/>
        &mdash; <b>0.265</b> sec, <b>37.70</b> million rows/s.</p>

        <p>SELECT formatReadableSize(sum(data_compressed_bytes)) FROM system.columns WHERE table = 'ip_address_num'<br/>
        &mdash; <b>30.92</b> MiB vs. <b>43.65</b> MiB.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>1. If there are few different values,<br/>just write numeric identifiers.</p>
        <p>Converting to strings and back can be done on the application side.</p>
        <p>This &mdash; is typical practice applicable to almost all DBMS.</p>

        <p>Example:</p>

        <p style="color: red;">Region String<br/>'Moscow and Moscow Region'</p>
        <p style="color: green;">RegionID UInt32<br/>250</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>2. If there are few different values, you can use the Enum data type.</p>
        <p>Enum works as efficiently as a numeric identifier.</p>
        <p>Disadvantage: sometimes you need to do ALTER.<br/>ALTER is free, but waits for executing queries on lock.</p>

        <p>Example:</p>

        <p style="color: red;">DeviceType String<br/>'mobile'</p>
        <p style="color: green;">DeviceType Enum8('desktop' = 1, 'mobile' = 2, 'tablet' = 3, 'tv' = 4)</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>3. If there aren't too many different values,<br/>just write numeric identifiers.</p>
        <p>For convenience, you can connect external dictionaries.
        <br/>From ClickHouse, MySQL, Mongo, Postgres, ODBC, file, HTTP server...</p>

        <p>Example: advertising campaigns and banners in Yandex.Direct.</p>
        <p>ClickHouse stores CampaignID UInt32, BannerID UInt64.</p>
        <p>Dictionaries from MySQL are connected.<br/>Campaigns &mdash; always in RAM. Banners &mdash; cache dictionary.</p>

        <p>Bonus: easy to change strings.</p>

        <p>Features: cache dictionary from MySQL<br/>works normally only with hit rate ~ 100%.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>4. If there's no way to do auto-increment, you can hash.</p>
        <p>When using 64bit hash, there will be collisions<br/>(p ~ 1/2 at N ~ 1000000000).</p>
        <p>To be safe, add<br/>client identifier to the dictionary key.</p>
        <p>Bonus &mdash; for many operations, hashes alone are enough.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>5. Short strings are fine to store as is.</p>
        <p>Example:</p>
        <p style="color: green;">URLDomain String<br/>'yandex.ru'</p>
        <p style="color: green;">BrowserLanguage String<br/>'ru'</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>6. If the set of strings is large and unlimited,<br/>and a significant portion is unique.</p>
        <p>Example: URL, Referer, SearchPhrase, Title.</p>
        <p>Then making dictionaries is completely pointless and contraindicated.</p>
        <p style="color: green;">Store as is!</p>
        <p>No need to try to move to a separate table and normalize data.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>7. Sometimes it's reasonable to store redundant columns with data extracts.</p>

        <p>Example: there is a URL column.<br/>
        Add a URLDomain column.</p>

        Example:</p>
        <p>SELECT <span style="color: red;">domain(URL)</span> AS k, count() AS c FROM test.hits GROUP BY k<br/>
        &mdash; <b>0.166</b> sec. Processed 762.68 MB (53.60 million rows/s., 4.61 GB/s.)</p>

        <p>SELECT <span style="color: green;">URLDomain</span> AS k, count() AS c FROM test.hits GROUP BY k<br/>
        &mdash; <b>0.067</b> sec. Processed 188.06 MB (132.44 million rows/s., 2.81 GB/s.)</p>

        <p>On disk: URL - <b>126.80</b> MiB, URLDomain - <b>5.61</b> MiB.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>8. Use the right data types.</p>

        <p style="color: red;">ClientIP String '5.255.255.5'<br/>
            ClientIPv6 String '2a02:6b8:a::a'<br/>
            DeviceID String 'c9792d6e-ab40-42e6-b171-aa872e880dbd'<br/>

        <p style="color: green;">ClientIP UInt32<br/>
            ClientIPv6 FixedString(16)<br/>
            DeviceID FixedString(16)</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>9. Sometimes it's better to preprocess strings in advance.</p>

        <p style="color: red;">BrowserVersion String<br/>
        '12.3.67542.29'<br/>
        <br/>splitByChar('.', BrowserVersion)[1]</p>

        <p style="color: green;">BrowserVersion1 UInt8<br/>
        BrowserVersion2 UInt16<br/>
        BrowserVersion3 UInt32<br/>
        BrowserVersion4 UInt16</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p>10. Very long strings and very long arrays.</p>

        <p>Don't store in ClickHouse at all.</p>
        <p>Two options:</p>
        <p>1. Truncate on insert.</p>
        <p>Example: in one service, only<br/>the first 512 user event parameters are stored;</p>
        <p>2. Store outside, and in ClickHouse &mdash; hashes.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">Bonus:</h2>

        <p>You can load data into a Log-type table with String fields,<br/>
        then analyze them already in ClickHouse,<br/>and determine the correct types before loading further.</p>
    </section>



    <section class="slide">
        <h2 style="font-size: 24pt;">3. Large Number of Small Tables.</h2>

        <pre>:) SHOW TABLES

┌─name──────┐
│ stats_0   │
│ stats_1   │
│ stats_2   │
│ stats_3   │
│ stats_4   │
│ stats_5   │
│ stats_6   │
│ stats_7   │
│ stats_8   │
│ stats_9   │
│ stats_10  │
  ...
│ stats_999 │
└───────────┘
</pre>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">Reasons for Using:</h2>

        <p>Old habits from MySQL experience:</p>
        <p>&mdash; absence of clustered primary key in MyISAM tables in MySQL;</p>
        <p>&mdash; simpler maintenance operations with small tables;</p>
        <p>&mdash; microsharding.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">Why Not to Do This in ClickHouse?</h2>

        <p>1. Data in the table is ordered by primary key.</p>
        <p>Reading a range is efficient regardless of the total<br/>amount of data in the table. Primary key is clustered.</p>

        <p>2. The table already contains partitioning inside itself.</p>
        <p>Each table &mdash; is a rather bulky object.</p>
        <p>For each table, some background merge work<br/>must be constantly performed.</p>

    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">Why Not to Do This in ClickHouse?</h2>

        <p>3. No problems with maintenance operations.</p>
        <p>ALTER ADD/DROP COLUMN executes in O(1)</p>
        <p>Table consists of immutable pieces and recovery after failure is trivial.</p>

        <p>4. ClickHouse &mdash; is about throughput.</p>
        <p>Processing time for 10 rows is about the same as 10,000 rows.</p>
        <p>If your tables contain less than 10,000 rows,<br/>then less doesn't matter anymore.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">How to Do It Right?</h2>

        <p><span style="color: green;">One big table!</span> Don't be afraid.</p>
        <p>Example: we store a table with Graphite metrics,<br/>
        on one server &mdash; 2,000,000,000,000 rows.</p>

        <p>Bonus:</p>

        <p>Support for custom partitioning key in ClickHouse.</p>
        <p>If you really need many small tables without index<br>&mdash; use StripeLog.</p>
    </section>



    <section class="slide">
        <h2 style="font-size: 24pt;">4. Microsharding.</h2>

        <p>Reasonable approach to sharding. From another world.</p>
        <p>Don't use this approach in ClickHouse.</p>

        <p>The idea &mdash; data is divided into 1000 virtual shards<br/>any convenient way.</p>
        <p>Each virtual shard maps to a set of servers arbitrarily, and the mapping is stored separately.</p>
        <p>On each physical server, multiple instances<br/>&mdash; in different databases or on different ports.</p>
        <p>Reason &mdash; simplify the data rebalancing task.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">4. Microsharding.</h2>

        <p>Why not use this for ClickHouse?</p>
        <p>1. If data is located in different ClickHouse instances, <br/>
        then query processing by different instances requires<br/><b>inter-process interaction over TCP</b>.<br/>
        Even over localhost this is much slower than in-process.</p>

        <p>2. In case of one instance, threads process data as possible, work is evenly distributed across threads.<br/>
        In case of different instances, one instance will finish work earlier than others &mdash; <b>tail latency</b>.</p>

        <p>3. Even if tables are located in one ClickHouse instance,<br/>
        you get problems due to a large number of small tables.<br/>
        When combining tables using a Merge table, <b>some optimizations are disabled</b>.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 24pt;">5. Too Much Pre-aggregation.</h2>

        <p>Pre-aggregation &mdash; is normal. Even in ClickHouse.</p>
        <p>But too granular pre-aggregation &mdash; is pointless.</p>

        <p>Example*:</p>
        <p>SummingMergeTree(EventDate,<br/>
(OrderID, EventDate, CampaignID, BannerID, AdID, TypeID,<br/>
DisplayID, ContextID, TargetType, AbcID, IsGood, CostType, PageID),<br/>
8192)</p>
        <p style="font-size: 14pt;">* column names changed.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">5. Too Much Pre-aggregation.</h2>

        <p>Disadvantages:</p>
        <p>&mdash; data volume decreases, but only several times compared to non-aggregated data;</p>
        <p>&mdash; developers constantly ask to expand primary key, but ClickHouse has no ALTER PRIMARY KEY support;</p>
        <p>&mdash; among aggregates, only sums are calculated (could be worked around with AggregatingMergeTree)</p>
        <p>&mdash; suitable only for primitive reports, not suitable for analytics.</p>

        <p>For ClickHouse, non-aggregated data &mdash; is the best scenario.<br/>
        Pre-aggregation can also be used for simple cases.</p>
    </section>



    <section class="slide">
        <h2 style="font-size: 24pt;">6. O(N) Queries from Script in Loop.</h2>

        <p style="color: red; font-size: 16pt;">
             SELECT count() FROM hits WHERE URL = 'https://yandex.ru/?cid=1764026490'
        <br/>SELECT count() FROM hits WHERE URL = 'https://yandex.ru/?cid=132741461'
        <br/>SELECT count() FROM hits WHERE URL = 'https://yandex.ru/?cid=4897535466'
        <br/>SELECT count() FROM hits WHERE URL = 'https://yandex.ru/?cid=1301256137'
        <br/>SELECT count() FROM hits WHERE URL = 'https://yandex.ru/?cid=2149858559'
        <br/>SELECT count() FROM hits WHERE URL = 'https://yandex.ru/?cid=544614111'
        <br/>...</p>

        <p style="color: green;">SELECT URL, count() FROM hits WHERE URL IN (...) GROUP BY URL</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">Why Many Queries &mdash; Bad?</h2>

        <p>If index is not used, then each query<br/> &mdash; is a separate pass through data;</p>
        <p>If index is used, then each query<br/>captures a bit of extra data for reading,
        <br/>for example, reads 100,000 rows instead of one row<br/>&mdash; again many passes through the same data.</p>

        <p>Can be rewritten as one query.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">6. O(N) Queries from Script in Loop.</h2>

        <p>Bonuses:</p>
        <p>&mdash; in ClickHouse, you can safely pass<br/>megabytes of data to the IN section;</p>
        <p>&mdash; in ClickHouse, index always works no slower than full scan;</p>
        <p>Features:</p>
        <p>&mdash; IN (SELECT ...) doesn't use index;</p>
        <p>&mdash; in distributed query processing,<br/>query text is transmitted without compression.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">6. O(N) Queries from Script in Loop.</h2>

        <p>What if queries come from API?</p>
        <p>&mdash; throttle API users:<br/>quotas, adaptive throttling.</p>

        <p>Bonus: you can configure quotas per user in ClickHouse, passing quota_key.</p>

        <p style="color: green;">If API is accessible externally, quotas are mandatory!</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 24pt;">7. Manual Replication.</h2>

        <p>What is this?</p>
        <p>You write the same data in the same way<br/> to completely independent servers.</p>

        <p>Advantages:<br/>
        &mdash; absence of ZooKeeper in infrastructure;<br/>
        &mdash; ease of use, integration into existing pipeline.</p>

        <p>Disadvantages:<br/>
        &mdash; need to restore replicas manually;<br/>
        &mdash; due to errors and non-deterministic work on the application side, data diverges during operation;<br/>
        &mdash; you can't decide which data copy is correct.</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">7. Manual Replication.</h2>

        <p>Bonus:</p>
        <p>In ClickHouse, it's easy to create a Distributed table,<br/>that looks at &laquo;manual&raquo; replicas.</p>
        <p>Using load_balancing = 'nearest_hostname'<br/>you can avoid flaps in case of diverging replicas.</p>

        <p>Proper solution:<br/>Use ReplicatedMergeTree.</p>
        <p>Advantages:<br/>
        &mdash; recovery after failure;<br/>
        &mdash; replicas monitor data consistency themselves.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 24pt; line-height: 1.5;">8. Using Primitive Table Engines<br/> for Main Data.</h2>

        <p>For main data &mdash; use the MergeTree family.</p>

        <p>
        &mdash; table doesn't have to contain Date<br/>
        &mdash; you can use Date DEFAULT '2000-01-01',<br/>
        &mdash; or tables without partitioning.</p>

        <p>Reasons:</p>
        <p>
        &mdash; sorting by key, index;<br/>
        &mdash; atomic insert;<br/>
        &mdash; no locks during concurrent INSERT and SELECT;<br/>
        &mdash; immutable data structures on disk;<br/>
        &mdash; replication;</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 24pt;">8. Using Primitive Table Engines.</h2>

        <p>For one-time loading of small-medium volumes<br/>&mdash; <b>Log</b>.</p>
        <p>For temporary batches for intermediate processing<br/>&mdash; <b>StripeLog</b>, <b>TinyLog</b>.</p>
        <p>For small amount of temporary data<br/>&mdash; <b>Memory</b>.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 24pt; line-height: 1.5;">9. Over-normalized Data.<br/> JOIN with High Cardinality.</h2>

        <p>Example:</p>

        <pre>SELECT url, count() FROM stats
    ANY INNER JOIN urls USING (url_id)</pre>

        <p>Why is this bad?</p>

        <p>ClickHouse only supports Hash JOIN. No Merge JOIN support.</p>

        <p>Hash JOIN &mdash; is random access in RAM.<br/>
        For high cardinality, worse than reading data inplace.</p>

        <p>Solution: for high cardinality joined data,<br/>better to use their storage in the main table.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 24pt;">More Anti-patterns</h2>
        <p>10. Using OPTIMIZE queries to<br/>simulate UPDATE functionality.</p>
        <p>11. Using distributed JOINs<br/>with large right table.<br/>ClickHouse poorly composes query plan for distributed JOINs.</p>

        <h2 style="font-size: 24pt;">Bad, but Sometimes Ok</h2>

        <p>12. Using ClickHouse only to<br/>read data back with SELECT *.</p>
        <p>13. Performing excessively heavy computations<br/>inside ClickHouse (high cycle/byte value).</p>
    </section>


    <section class="slide">
        <h2>Community</h2>
        <p>Website: <a href="https://clickhouse.com/">https://clickhouse.com/</a></p>
        <p>Google groups: <a href="https://groups.google.com/forum/#!forum/clickhouse">https://groups.google.com/forum/#!forum/clickhouse</a></p>
        <p>Mailing list: clickhouse-feedback@yandex-team.com</p>
        <p>Telegram chat: <a href="https://telegram.me/clickhouse_en">https://telegram.me/clickhouse_en</a> and <a href="https://telegram.me/clickhouse_ru">https://telegram.me/clickhouse_ru</a> (already 1041 participants)</p>
        <p>GitHub: <a href="https://github.com/ClickHouse/ClickHouse/">https://github.com/ClickHouse/ClickHouse/</a></p>
        <p>+ meetings. Moscow, Saint Petersburg, Novosibirsk, Ekaterinburg, Minsk, Berlin... Next: Nizhny Novgorod, Moscow.</p>
    </section>

    <section class="slide">
        <h2>Thank You!</h2>
    </section>


    <div class="progress"></div>
    <script src="https://presentations.clickhouse.com/shower/shower.js"></script>
<footer class="badge">
    <a href="https://presentations.clickhouse.com/">ClickHouse Theater</a>
</footer>
</body>
</html>
