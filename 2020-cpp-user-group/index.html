<!DOCTYPE html>
<html lang="en">
<head>
    <title>How I Optimized One Aggregate Function in ClickHouse</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:image" content="pictures/logo.png">
    <meta property="og:title" content="How I Optimized One Aggregate Function in ClickHouse">
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="pictures/logo.png">
    <link rel="stylesheet" href="shower/themes/yandex/styles/screen-16x10.css">

    <style type="text/css">
         code { display: block; white-space: pre; background-color: #EEE; }
    </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>How I Optimized One Aggregate Function in ClickHouse</h1>
    </header>

    <section class="slide" id="cover" style="background: #FFF url('pictures/logo.png') no-repeat top right; background-size: 25%;">
        <h1 style="margin-top: 160px; font-size: 36pt;">How I Optimized One<br/>Aggregate Function in ClickHouse</h1>
    </section>

<section class="slide">
<h2 style="font-size: 48pt;">ClickHouse Doesn't Slow Down.</h2>
<p>Is ClickHouse the fastest system in all scenarios?</p>
</section>

<section class="slide">
<h2 style="font-size: 48pt;">ClickHouse Doesn't Slow Down.</h2>
<p>Is ClickHouse the fastest system in all scenarios?</p>
<p>&mdash; in specific cases someone can win...<br/>
&emsp; ... until I notice it.</p>
</section>

<section class="slide">
<h2 style="font-size: 48pt;">ClickHouse Doesn't Slow Down.</h2>
<p>Is ClickHouse the fastest system in all scenarios?</p>
<img src="pictures/example1.png"/>
</section>

<section class="slide">
<h2 style="font-size: 48pt;">DBMS-X</h2>
<p>Works with data only using mmap.</p>
<p>Doesn't support data compression.</p>
<p>Doesn't support indexes and doesn't sort stored data.</p>
<p>Barely supports SQL.</p>

<p style="margin-top: 2em; color: red;">Executes one query faster than ClickHouse?</p>
</section>

<section class="slide">
<h2 style="font-size: 48pt;">DBMS-X</h2>
<p>Executes one query faster than ClickHouse?</p>
<code>SELECT sum(x) FROM table</code>
<p style="margin-top: 1em;"><pre>x Nullable(Float64)</pre></p>

<p>&mdash; summing 1 billion doubles.</p>

<pre>
ClickHouse: 0.116 sec
DBMS-X:     0.066 sec</pre>

<p style="color: gray;">AWS c5.metal, 96 vCPU</p>
</section>

<section class="slide">
<h2 style="font-size: 36pt;">Sanity Check &mdash; Counting Bytes</h2>
<p>Data scanning speed in GB/sec.</p>
<p><b>double</b> &mdash; 8 bytes + NULL mask, possibly 1 byte,<br/>total 9 bytes per value in memory.</p>
<p>Need to process 9 GB of data in memory.</p>

<pre>
ClickHouse: 0.116 sec,  78 GB/sec.
DBMS-X:     0.066 sec, 136 GB/sec.

STREAM benchmark:      160 GB/sec.</pre>

<p>160 GB/sec. &mdash; maximum
<br/>memory scanning speed on this machine.</p>

</section>


<section class="slide">
<h2 style="font-size: 32pt;">What's the Fastest Way to Sum Numbers?</h2>
<p>1. Use available CPU cores
<br/>&emsp;(divide work across threads).</p>
<p>2. Use vectorized query processing
<br/>&emsp;(only simple loops, no virtual calls inside).</p>
<p>3. Process data in blocks
<br/>&emsp;(proper CPU cache usage).</p>
<p>4. Cache uncompressed data in memory
<br/>&emsp;(eliminate decompression, deserialization, copying).</p>
</section>

<section class="slide">
<h2 style="font-size: 32pt;">What's the Fastest Way to Sum Numbers?</h2>
<p>Code executed by the database should be the same<br/>as if you manually wrote perfect C++ code.</p>

<code>template &lt;typename T>
T sum(const T * ptr, const T * end)
{
    T res{};
    while (ptr &lt; end)
    {
        res += *ptr;
        ++ptr;
    }
    return res;
}</code>
</section>

<section class="slide">
<h2 style="font-size: 32pt;">What's the Fastest Way to Sum Numbers?</h2>
<code style="margin-top: -1em; margin-bottom: 1em;">while (ptr &lt; end)
{
    res += *ptr;
    ++ptr;
}
</code>
<p>But is this perfect C++ code?</p>

<p>&mdash; can unroll the loop;<br/>
&mdash; can vectorize the loop;<br/>
&mdash; alignment;<br/>
&mdash; prefetch;</p>

<p style="margin-top: 2em;">But shouldn't the C++ compiler do this itself?</p>
</section>



<section class="slide">
<h2 style="font-size: 30pt;">What's the Fastest Way to Sum Numbers?</h2>
<code style="font-size: 16pt; line-height: 1.5">$ g++ -O2 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 2.561, 3.123 GB/sec.

$ g++ -O3 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 1.590, 5.033 GB/sec.

$ g++ -O3 -msse4.2 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 1.560, 5.129 GB/sec.

$ g++ -O3 -mavx2 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 1.188, 6.733 GB/sec.

$ g++ -O3 -march=native main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 1.192, 6.710 GB/sec.
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">What's the Fastest Way to Sum Numbers?</h2>
<code style="font-size: 16pt; line-height: 1.5">$ clang++ -O2 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 0.726, 11.013 GB/sec.

$ clang++ -O3 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 0.724, 11.044 GB/sec.

$ clang++ -O3 -msse4.2 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 0.733, 10.918 GB/sec.

$ clang++ -O3 -mavx2 main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 0.728, 10.983 GB/sec.

$ clang++ -O3 -march=native main.cpp &amp;&amp; ./a.out
Res: 499999999067108992.000, time: 0.741, 10.792 GB/sec.
</code>
</section>


<section class="slide">
<h2 style="font-size: 30pt;">What's the Fastest Way to Sum Numbers?</h2>
<code style="font-size: 16pt; line-height: 1.25; margin-bottom: 1em;">$ g++ -O3 -march=native -S main.cpp &amp;&amp; cat main.s

.L11:
    vmovups       (%rax), %xmm1
    vmovupd       (%rax), %ymm3
    addq          $<span style="color: red;">32</span>, %rax
    <span style="color: red;">vaddsd</span>        %xmm1, %xmm0, %xmm0
    vunpckhpd     %xmm1, %xmm1, %xmm1
    <span style="color: red;">vaddsd</span>        %xmm1, %xmm0, %xmm0
    vextractf128  $0x1, %ymm3, %xmm1
    <span style="color: red;">vaddsd</span>        %xmm1, %xmm0, %xmm0
    vunpckhpd     %xmm1, %xmm1, %xmm1
    <span style="color: red;">vaddsd</span>        %xmm1, %xmm0, %xmm0
    cmpq          %rdx, %rax
    jne           .L11
</code>
<p>Loop is unrolled but not vectorized.</p>
</section>


<section class="slide">
<h2 style="font-size: 30pt;">What's the Fastest Way to Sum Numbers?</h2>
<code style="font-size: 16pt; line-height: 1.25; margin-bottom: 1em;">$ clang++ -O3 -march=native -S main.cpp &amp;&amp; cat main.s

.LBB2_2: # =>This Inner Loop Header: Depth=1
    <span style="color: red;">vaddsd</span>  (%rdi), %xmm0, %xmm0
    addq    $<span style="color: red;">8</span>, %rdi
    cmpq    %rsi, %rdi
    jb      .LBB2_2
</code>
<p>Loop is not unrolled, not vectorized... but this is better on my machine.</p>
</section>


<section class="slide">
<h2 style="font-size: 30pt;">Why Doesn't the Compiler Vectorize the Loop?</h2>
<p>Loop with <span style="color: red;">double</span>, <span style="color: red;">float</span> &mdash; not vectorized.</p>
<p>Loop with <span style="color: green;">int</span> &mdash; vectorized.</p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Why Doesn't the Compiler Vectorize the Loop?</h2>
<p>Loop with <span style="color: red;">double</span>, <span style="color: red;">float</span> &mdash; not vectorized.</p>
<p>Loop with <span style="color: green;">int</span> &mdash; vectorized.</p>
<p>&mdash; Because it contradicts the C++ standard and IEEE-754.</p>
<p><pre>(a + b) + c != a + (b + c).</pre></p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Why Doesn't the Compiler Vectorize the Loop?</h2>
<p style="margin-top: -1em;">This can be "fixed", you just need to:</p>

<code style="font-size: 14pt; margin-bottom: 1em;">$ clang++ -O3 -march=native -f<span style="color: red;">fast-math</span> main.cpp &amp;&amp; ./a.out
Res: 499999999500000000.000, time: 0.362, <span style="color: green;">22.086</span> GB/sec.

$ g++ -O3 -march=native -f<span style="color: red;">fast-math</span> main.cpp &amp;&amp; ./a.out
Res: 499999999268435456.000, time: 0.392, <span style="color: green;">20.428</span> GB/sec.

$ clang++ -O3 -march=native -f<span style="color: red;">fast-math</span> -S main.cpp &amp;&amp; cat main.s

.LBB2_4: # =>This Inner Loop Header: Depth=1
    vaddpd  (%rdi,%rcx,8), %ymm0, %ymm0
    vaddpd  32(%rdi,%rcx,8), %ymm1, %ymm1
    vaddpd  64(%rdi,%rcx,8), %ymm2, %ymm2
    vaddpd  96(%rdi,%rcx,8), %ymm3, %ymm3
    addq    $16, %rcx
    cmpq    %rcx, %rdx
    jne     .LBB2_4
</code>
<p>But you can't do this :(</p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Why Doesn't the Compiler Vectorize the Loop?</h2>
<p><b>-ffast-math</b> cannot be used.<br/>Because it breaks calculation precision.</p>
<p>Kahan Summation:</p>
<code style="font-size: 14pt; margin-bottom: 1em;">while (ptr &lt; end)
{
    double compensated_value = *ptr - compensation;
    double new_sum = sum + compensated_value;
    compensation = (new_sum - sum) - compensated_value;
    sum = new_sum;
    ++ptr;
}
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Why Doesn't the Compiler Vectorize the Loop?</h2>
<p><b>-ffast-math</b> cannot be used.<br/>Because it breaks calculation precision.</p>
<p>Kahan Summation:</p>
<code style="font-size: 14pt; margin-bottom: 1em;">while (ptr &lt; end)
{
    double compensated_value = *ptr - compensation;
    double new_sum = <span style="color: red;">sum + compensated_value</span>;
    compensation = (<span style="color: red;">sum + compensated_value</span> - sum) - compensated_value;
    sum = new_sum;
    ++ptr;
}
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Why Doesn't the Compiler Vectorize the Loop?</h2>
<p><b>-ffast-math</b> cannot be used.<br/>Because it breaks calculation precision.</p>
<p>Kahan Summation:</p>
<code style="font-size: 14pt; margin-bottom: 1em;">while (ptr &lt; end)
{
    double compensated_value = *ptr - compensation;
    double new_sum = sum + compensated_value;
    compensation = <span style="color: red;">0</span>;
    sum = new_sum;
    ++ptr;
}
</code>
</section>


<section class="slide">
<h2 style="font-size: 30pt;">Can Manually Unroll the Loop</h2>
<code style="font-size: 10pt; margin-top: -1em;">/// Vectorized version
template &lt;typename Value>
void NO_INLINE addMany(const Value * __restrict ptr, size_t count)
{
    /// Compiler cannot unroll this loop, do it manually.
    /// (at least for floats, most likely due to the lack of -fassociative-math)

    /// Something around the number of SSE registers * the number of elements fit in register.
    constexpr size_t <b style="color: green;">unroll_count</b> = 128 / sizeof(T);
    T partial_sums[<b style="color: green;">unroll_count</b>]{};

    const auto * end = ptr + count;
    const auto * unrolled_end = ptr + (count / <b style="color: green;">unroll_count</b> * <b style="color: green;">unroll_count</b>);

    while (ptr &lt; unrolled_end)
    {
        for (size_t i = 0; i &lt; <b style="color: green;">unroll_count</b>; ++i)
            partial_sums[i] += ptr[i];
        ptr += <b style="color: green;">unroll_count</b>;
    }

    for (size_t i = 0; i &lt; <b style="color: green;">unroll_count</b>; ++i)
        sum += partial_sums[i];

    while (ptr &lt; end)
    {
        sum += *ptr;
        ++ptr;
    }
}</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Can Manually Unroll the Loop</h2>
<code style="font-size: 12pt; margin-bottom: 1em;">#pragma GCC push_options
<span style="color: green;">#pragma GCC optimize ("-ffast-math")</span>

template &lt;typename T>
__attribute__((__noinline__)) T sum(const T * ptr, const T * end)
{
    T res{};
    while (ptr &lt; end)
    {
        res += *ptr;
        ++ptr;
    }
    return res;
}

#pragma GCC pop_options
</code>
<p>Only for gcc.</p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Unrolled the Loop and...</h2>
<p>Launched a machine on AWS, reproduced the results.</p>

<p><pre style="line-height: 1.5">
              median, 1000 queries
ClickHouse:   <span style="color: green;">0.090</span> sec
DBMS-X:       0.093 sec</pre></p>

<p>ClickHouse is <span style="color: green;">three milliseconds</span> faster!</p>
</section>


<section class="slide">
<h2 style="font-size: 48pt;">ClickHouse Doesn't Slow Down.</h2>
<p>Is ClickHouse the fastest system in all scenarios?</p>
<p>Can anyone become faster than ClickHouse on at least one query?</p>
</section>

<section class="slide">
<h2 style="font-size: 48pt;">DBMS-Y</h2>
<p style="color: green;">Can use not only CPU but also GPU.</p>
<p>Only works with data that fits in memory.</p>
<p>Doesn't support data compression.</p>
<p>Doesn't support indexes and doesn't sort stored data.</p>
<p>Barely supports GROUP BY on strings.</p>

<p style="margin-top: 2em; color: red;">Executes one query faster than ClickHouse?</p>
</section>

<section class="slide">
<img style="width: 100%;" src="pictures/comparison2.png" />
</section>

<section class="slide">
<h2 style="font-size: 48pt;">DBMS-Y</h2>
<p style="margin-top: -1em;">Executes one query faster than ClickHouse?</p>
<code>SELECT passenger_count, avg(total_amount)
    FROM trips
    GROUP BY passenger_count</code>
<p style="margin-top: 1em;"><pre>passenger_count UInt8, total_amount Float32</pre></p>

<p>&mdash; calculating avg by key 0..255.</p>

<pre>
ClickHouse: 0.827 sec (MergeTree)
ClickHouse: 0.395 sec (MergeTree + uncompressed cache)
ClickHouse: <span style="color: red;">0.332</span> sec (Memory)
DBMS-Y:     <span style="color: green;">0.204</span> sec</pre>

<p style="color: gray;">Xeon E5-2650v2, 32 logical CPU</p>
</section>


<section class="slide">
<h2 style="font-size: 30pt;">What Would be Ideal Code?</h2>
<p>For executing the query:</p>
<code style="margin-bottom: 1em;">SELECT key, avg(value) FROM table GROUP BY key</code>

<p><b>Data structure:</b></p>
<p>Lookup table, 256 cells<br/>
&mdash; array of sum, count pairs.</p>

<p><b>Algorithm:</b></p>
<p>Just loop through input data<br/>
and update state in the cell.</p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">What Would be "Ideal" Code?</h2>
<code style="margin-top: -1em; font-size: 13pt;">struct State
{
    float sum = 0;
    size_t count = 0;

    void add(float value)
    {
        sum += value;
        ++count;
    }
};

void process(const vector&lt;uint8_t> &amp; keys,
             const vector&lt;float> &amp; values)
{
    State map[256]{};

    size_t size = keys.size();
    for (size_t i = 0; i &lt; size; ++i)
        map[keys[i]].add(values[i]);

    return map[0].result();
}</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">What Code is Actually Used?</h2>
<p><span style="color: green;">A lookup table is used.</span></p>
<p>But there are some details:</p>
<p>1. States are not stored directly in it,<br/>&emsp;but by pointer, allocated in a separate arena.</p>
<p>2. Each cell stores one more bit, whether it's occupied.</p>
<p>3. Buffer for the lookup table is allocated separately.</p>
<p>4. Lookup table size is stored separately and updated on insert.</p>

<p style="margin-top: 2em;">Four optimization opportunities!</p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Four Optimization Opportunities</h2>
<img style="float: right;" src="pictures/frustration.jpg"/>
<p>I tried them all.</p>
<p>They helped, but not enough.</p>
<p>Our code is already "ideal".</p>
<p style="margin-top: 3em;">But it doesn't work fast enough,<br/> need some <b>magic</b>!</p>
</section>


<section class="slide">
<h2 style="font-size: 30pt;">Unroll the Loop</h2>
<p style="margin-top: -1em;">Create multiple state tables.<br/>Aggregate into different ones, then merge together.</p>
<code style="font-size: 15pt; line-height: 1.25">State map[256 * UNROLL_COUNT]{};

size_t size = keys.size();
size_t i = 0;

size_t size_unrolled = size / UNROLL_COUNT * UNROLL_COUNT;
for (; i &lt; size_unrolled; i += UNROLL_COUNT)
    for (size_t j = 0; j &lt; UNROLL_COUNT; ++j)
        map[256 * j + keys[i + j]].add(values[i + j]);

for (size_t key = 0; key &lt; 256; ++key)
    for (size_t j = 1; j &lt; UNROLL_COUNT; ++j)
        map[key].merge(map[256 * j + key]);

for (; i &lt; size; ++i)
    map[keys[i]].add(values[i]);
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Unroll the Loop Differently</h2>
<code style="font-size: 15pt; line-height: 1.25">struct State4
{
    float sum[4]{};
    size_t count[4]{};
    ...
};

State4 map[256]{};

size_t size = keys.size() / 4 * 4;
for (size_t i = 0; i &lt; size; i += 4)
{
    map[keys[i]].add&lt;0>(values[i]);
    map[keys[i + 1]].add&lt;1>(values[i]);
    map[keys[i + 2]].add&lt;2>(values[i]);
    map[keys[i + 3]].add&lt;3>(values[i]);
}
...
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Buffering and Batching</h2>
<code style="font-size: 10pt; line-height: 1.25; margin-top: -2em;">State map[256]{};

static constexpr size_t BUF_SIZE = 16384 / 256 / sizeof(float); <span style="color: green;">/// Should fit in L1d.</span>

float buffers[256 * BUF_SIZE];
float * ptrs[256];

for (size_t i = 0; i &lt; 256; ++i)
    ptrs[i] = &amp;buffers[i * BUF_SIZE];

size_t size = keys.size();
const auto * key = keys.data();
const auto * key_end = key + size;
const auto * value = values.data();

while (key &lt; key_end)
{
    *ptrs[*key] = *value;

    if (++ptrs[*key] == &amp;buffers[(*key + 1) * BUF_SIZE])  <span style="color: green;">/// Calculation is better than L1d load.</span>
    {
        ptrs[*key] -= BUF_SIZE;
        map[*key].addBatch&lt;BUF_SIZE>(ptrs[*key], BUF_SIZE);
    }

    ++key;
    ++value;
}

for (size_t i = 0; i &lt; 256; ++i)
    map[i].addBatch&lt;4>(&amp;buffers[i * BUF_SIZE], ptrs[i] - &amp;buffers[i * BUF_SIZE]);
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">Variation on Bucket Sort</h2>
<code style="font-size: 10pt; line-height: 1.25; margin-top: -2em;">State map[256]{};
size_t size = keys.size();

<span style="color: green;">/// Calculate histograms of keys.</span>
using CountType = UInt32;
static constexpr size_t HISTOGRAM_SIZE = 256;
CountType count[HISTOGRAM_SIZE * UNROLL_COUNT]{};
size_t unrolled_size = size / UNROLL_COUNT * UNROLL_COUNT;
for (const UInt8 * elem = keys.data(); elem &lt; keys.data() + unrolled_size; elem += UNROLL_COUNT)
    for (size_t i = 0; i &lt; UNROLL_COUNT; ++i)
        ++count[i * HISTOGRAM_SIZE + elem[i]];
for (const UInt8 * elem = keys.data() + unrolled_size; elem &lt; keys.data() + size; ++elem)
    ++count[*elem];
for (size_t i = 0; i &lt; HISTOGRAM_SIZE; ++i)
    for (size_t j = 1; j &lt; UNROLL_COUNT; ++j)
        count[i] += count[j * HISTOGRAM_SIZE + i];

<span style="color: green;">/// Row indices in a batch for each key.</span>
PODArray&lt;UInt32> indices(size);
UInt32 * positions[HISTOGRAM_SIZE];
positions[0] = indices.data();
for (size_t i = 1; i &lt; HISTOGRAM_SIZE; ++i)
    positions[i] = positions[i - 1] + count[i - 1];
for (size_t i = 0; i &lt; size; ++i)
    *positions[keys[i]]++ = i;

<span style="color: green;">/// Update states.</span>
UInt32 * idx = indices.data();
for (size_t i = 0; i &lt; HISTOGRAM_SIZE; ++i)
    for (; idx &lt; positions[i]; ++idx)
        map[i].add(values[*idx]);
</code>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">By How Much Should We Unroll?</h2>
<p>Testing on different servers gives different results.</p>
<p>On AMD EPYC, Ryzen processors there's larger cache<br/>&mdash; can unroll by 8x.</p>
<p>On Intel processors this causes terrible slowdowns<br/>&mdash; and maximum is 4x.</p>
</section>

<section class="slide">
<h2 style="font-size: 30pt;">How Much Speedup Did We Achieve?</h2>
<p>On model code:</p>
<pre>
Baseline:   360 million rows/sec., 1804 MiB/sec.
Optimized: 1339 million rows/sec., 6695 MiB/sec. x3.72
</pre>
<p>Real query in ClickHouse:</p>
<pre>
ClickHouse (old): <span style="color: red;">0.332</span> sec.
DBMS-Y:           0.204 sec
ClickHouse (new): <span style="color: green;">0.197</span> sec. x1.69
</pre>
</section>

<section class="slide">
<h2 style="font-size: 48pt;">Conclusions</h2>
<p>If some system on some degenerate query
<br/>&emsp; works slightly faster than ClickHouse
<br/>&mdash; it means I haven't optimized the code yet,
<br/>&emsp; and I'll do it tomorrow.</p>

<p>ClickHouse's internal architecture allows
<br/>optimizing for the task and hardware.</p>
</section>

<section class="slide">
<h2 style="font-size: 36pt;">Bonus</h2>
<p style="margin-top: -1em;">Batch Aggregator:<br/>
<a href="https://github.com/ClickHouse/ClickHouse/pull/6435">https://github.com/ClickHouse/ClickHouse/pull/6435</a>
</p>
<p>Speeding up sum function:<br/>
<a href="https://github.com/ClickHouse/ClickHouse/pull/10992">https://github.com/ClickHouse/ClickHouse/pull/10992</a>
</p>
<p>Speeding up GROUP BY 8bit key:<br/>
<a href="https://github.com/ClickHouse/ClickHouse/pull/13055">https://github.com/ClickHouse/ClickHouse/pull/13055</a>
<a href="https://github.com/ClickHouse/ClickHouse/pull/13056">https://github.com/ClickHouse/ClickHouse/pull/13056</a>
<a href="https://github.com/ClickHouse/ClickHouse/pull/13084">https://github.com/ClickHouse/ClickHouse/pull/13084</a>
<a href="https://github.com/ClickHouse/ClickHouse/pull/13091">https://github.com/ClickHouse/ClickHouse/pull/13091</a>
<a href="https://github.com/ClickHouse/ClickHouse/pull/13096">https://github.com/ClickHouse/ClickHouse/pull/13096</a>
<a href="https://github.com/ClickHouse/ClickHouse/pull/13099">https://github.com/ClickHouse/ClickHouse/pull/13099</a>
</p>
<p>And test with examples:<br/>
<a href="https://github.com/ClickHouse/ClickHouse/blob/master/src/Common/tests/average.cpp">https://github.com/ClickHouse/ClickHouse/blob/master/<br/>&emsp;src/Common/tests/average.cpp</a>
</p>
</section>


<section class="slide">
    <h2>.</h2>
</section>

    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>
</body>
</html>
