<!DOCTYPE html>
<html lang="en">
<head>
    <title>Субботник по базам данных</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="shower/themes/yandex/styles/screen-16x9.css">

    <style type="text/css">
         code { display: block; white-space: pre; background-color: #EEE; }
    </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>Субботник по базам данных</h1>
    </header>
    <section class="slide" id="cover">
        <h1 style="margin-top: 150px; font-size: 32pt;"><div>Как перестать бояться</div><div style="text-align: right;">и начать разрабатывать</div><div style="text-align: right;">специализированные структуры данных</div></h1>
    </section>

    <section class="slide">
        <h2>Зачем?</h2>
<p>Зачем самостоятельно писать специализированные структуры данных?</p>
        
<p>&mdash; потому что можем?<br/>
&mdash; просто так захотелось?<br/>
&mdash; NIH (not invented here).</p>

<p>Лучше вместо этого использовать<br/><br/>... надёжные, современные, масштабируемые, отказоустойчивые, поддерживаемые, проверенные временем, одобренные сообществом технологии, разработанные лучшими инженерами, написавшими идеальный код, который решает в точности нужную вам задачу.</p>
    </section>


    <section class="slide">
        <h2>Realtime антифрод</h2>
        
<p>Для классификации посещений сайтов на человеческие / роботные.</p>

<p>Разработан в <b>2012</b> году для нужд Яндекс.Метрики.</p>

<p>Я не могу ни подтвердить ни опровергнуть<br/> тот факт, что он до сих пор работает в продакшене.</p>
    </section>


    <section class="slide">
        <h2>Realtime антифрод</h2>

<p>Набор серверов, отправляем в них информацию о трафике.</p>
<p>Серверы обновляют и выдают статистику по свойствам трафика.</p>
<p>По статистике работает машинно-обученная формула.</p>
    </section>


    <section class="slide">
        <h2>Какие свойства трафика есть</h2>

<p>&mdash; Время события</p>
<p>&mdash; IP адрес, IP-сеть, геолокация;</p>
<p>&mdash; Cookie пользователя;</p>
<p>&mdash; URL и Referer, а также их домены;</p>
<p>&mdash; User-Agent;</p>
<p>...</p>
    </section>


    <section class="slide">
        <h2>Какую статистику можно считать</h2>

<p>Счётчики &mdash; число событий по ключу:
<br/>&mdash; например &mdash; количество хитов для IP-сети класса C за минуту.</p>

<p>Кардинальности &mdash; число уникальных значений для ключа:
<br/>&mdash; пример: число уникальных cookie для IP-адреса;
<br/>&mdash; пример: число уникальных IP-адресов для cookie;
<br/>&mdash; пример: число уникальных сайтов, посещённых пользователем за час.</p>

<p>Статистики по времени:
<br/>&mdash; пример: дисперсия разницы между соседними событиями.</p>
    </section>


    <section class="slide">
        <h2>Арифметика: Throughput</h2>

<p>Входящий трафик 600 000 событий в секунду,<br/> &mdash; 30 млрд. событий в сутки.</p>
<p>На каждое событие, обновляем статистику по 15 ключам<br/> &mdash; 10 млн. key lookups/sec.</p>

<p>Какое железо использовать для 10 млн. lookups/sec.?</p>
    </section>


    <section class="slide">
        <h2>Арифметика: Throughput</h2>

<p><b>HDD</b> &mdash; 100..300 lookups/sec.<br/>Потребуется 100 000 HDD без резервирования или ~ 10 000 серверов.</p>

<p><b>SSD</b> &mdash; ~ 100 000 lookups/sec.<br/>Потребуется 100 SSD без резервирования или 10 серверов?
<br/>&mdash; но зачёркиваем, так как чтение/запись 1:1.</p>

<p><b>RAM</b> &mdash; 10 млн. / 40 млн. / 500 млн. LL cache misses / sec.</p>
    </section>


    <section class="slide">
        <h2>Арифметика: Volume</h2>

<p>Хотим хранить данные 1..2 суток.<br/>
Наиболее жирные ключи &mdash; UserID, URL, Referer, IP.</p>

<p>Кардинальности:
<br/>&mdash; URL &mdash; 1.5 млрд. в сутки.
<br/>&mdash; UserID &mdash; 450 млн. в сутки;
<br/>&mdash; IP &mdash; 100 млн. в сутки;</p>
    </section>

    <section class="slide">
        <h2>Арифметика: Volume</h2>
<p>Всего ~5 млрд ключей.
<br/>Статистика по одному ключу &mdash; в районе 1 КБ.
<br/>&mdash; 5 ТБ в сутки.</p>

<p>В 2012 году на один сервер использовалось 128 GB оперативки.
<br/>&mdash; 40 серверов без дублирования.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 30pt;">Как поместить статистику по ключу в 1 КБ?</h2>

<p>Даже один URL может быть больше нескольких килобайт.</p>
<p>&mdash; никогда не храним строки, только 8-байтовые хэши.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 30pt;">Как поместить статистику по ключу в 1 КБ?</h2>
<p>Нужно считать очень плохую статистику.</p>

<p>1. Счётчики.</p>

<code style="margin-bottom: 1em;">UInt64 count = 0;
void update() { ++count; }</code>

<p>8 байт &mdash; отвратительно много.</p>
<p>Можно ли посчитать от одного до миллиарда, используя один байт?</p>
    </section>

    <section class="slide">
        <h2 style="font-size: 30pt;">Как поместить статистику по ключу в 1 КБ?</h2>

<p>Можно ли посчитать от одного до миллиарда, используя один байт?</p>

<p>Да &mdash; для этого надо просто использовать генератор случайных чисел.</p>

<p>&mdash; для counter &lt; 8, прибавляем единицу с вероятностью 1.
<br/>&mdash; для counter [8..16), прибавляем единицу с вероятностью 1/2.
<br/>&mdash; для counter [16..24), прибавляем единицу с вероятностью 1/4.
<br/>&mdash; ...
<br/>&mdash; для counter [128..256), прибавляем единицу с вероятностью 1/2<sup>31</sup>.</p>

<p>Ожидаемое значение оценивается<br/>методом максимального правдоподобия.</p>
<p>Метод может быть как недетерминированным, так и детерминированным, если вместо генератора случайных чисел использовать хэш-функцию от данных.</p>
    </section>


    <section class="slide">
        <h2 style="font-size: 30pt;">Как поместить статистику по ключу в 1 КБ?</h2>
<p>2. Кардинальности.</p>

<p style="line-height: 1.5em;">Очевидно, что нужно использовать <b>HyperLogLog</b>.<br/>
2.5 КБ &mdash; ошибка ~1% &mdash; слишком хорошо, надо хуже.<br/>
24 байта &mdash; ошибка ~50% &mdash; вот теперь нормально.</p>

<p>Уже можно поместить 50 кардинальностей в 1 КБ.</p>
    </section>


    <section class="slide">
        <h2>Данных слишком много</h2>

<p>5 ТБ в сутки &mdash; <span style="color: red;">50 серверов</span> без дублирования.<br/>
&mdash; но нужна x2 репликация для отказоустойчивости;<br/>
&mdash; но нужно хранить данные чуть больше суток.</p>

<p>У нас нет 100 серверов. <span style="color: red;">Задача неразрешима</span>.</p>
    </section>


    <section class="slide">
        <h2>Данных слишком много</h2>

<p>Решение &mdash; не хранить статистики по ключам,<br/>которые встречаются редко.</p>
<p>Если мы увидели IP адрес впервые &mdash; ничего про него не храним.<br/>
Если мы встретили его 16 раз &mdash; начинаем считать статистику.</p>

<p>Но чтобы понять, что он встретился в шестнадцатый раз<br/>&mdash; надо это где-то хранить.</p>
    </section>


    <section class="slide">
        <h2>Данных слишком много</h2>

<p>Решение &mdash; <b>Counting Bloom Filter</b>.<br/>
Из 128 GB на сервере, выделим 10..20 GB на CBF.</p>

<p>CBF работает как &laquo;губка&raquo;, через которую просеиваются<br/>только важные ключи.</p>

<p>Объём оставшихся данных уменьшается до сотни GB<br/>и помещается на один сервер.</p>
    </section>


    <section class="slide">
        <h2>Counting Bloom Filter</h2>

<p>Недостаток &mdash; теперь если использовать 3 хэш-функции, придётся делать в 3 раза больше кэш-промахов.</p>
<p>10 млн. в секунду -> 30 млн. в секунду.</p>

<p>Это всё ещё может работать... даже на одном сервере.</p>

<p>Или изобрести <b>cache-local</b> Counting Bloom Filter?</p>
    </section>


    <section class="slide">
        <h2>Как отправлять данные на сервер?</h2>

<p>Предположим, что сервер должен обрабатывать<br/>~ 1 млн. запросов в секунду.</p>
<p>Какими технологиями написать такой сервер?</p>

<p>&mdash; coroutines/fibers?<br/> 
&mdash; DPDK?</p>
    </section>


    <section class="slide">
        <h2>Как отправлять данные на сервер?</h2>
<img style="float: left; height: 60%; margin-left: -60px; margin-top: -60px; margin-right: 20px;" src="pictures/optimal.webp"/>
<p>У нас realtime антифрод, но отправлять данные<br/>будем всё-равно пачками по 1000 .. 10 000 событий.</p>
<p>Задержка в одну секунду приемлима,<br/>а в секунду приходит 600 000 событий.</p>

<p><br/>Будем использовать обычный HTTP сервер с пулом потоков.</p>
    </section>


    <section class="slide">
        <h2>Конкурентная обработка запросов</h2>
<p>Как обеспечить конкурентную обработку<br/>одновременно приходящих запросов?</p>

<p>Может быть использовать lock-free структуры данных?</p>
    </section>


    <section class="slide">
        <h2>Конкурентная обработка запросов</h2>
<img style="float: right; height: 60%; margin-left: -60px; margin-top: -60px; margin-right: 20px;" src="pictures/not_optimal.webp"/>
<p>Как обеспечить конкурентную обработку<br/>одновременно приходящих запросов?</p>
<p>Может быть использовать lock-free<br/>структуры данных?</p>

<p><br/>Нет, лучше сделать в сервере один глобальный <b>mutex</b>,&nbsp;и обрабатывать в один момент времени<br/>один запрос, а остальные будут ждать.</p>
<p>Размениваем <b>latency</b> на <b>throughput</b>.</p>
    </section>


    <section class="slide">
        <h2>Как распараллелить обработку?</h2>
<p>Как распараллелить обработку запросов по процессорным ядрам?</p>

<p>Разбить все данные по остатку от деления хэша от ключа на N корзин.</p>
<p>Все структуры данных в сервере (Counting Bloom Filter, Hash Tables) имеются в N экземплярах.</p>
<p>Входящая пачка данных передаётся для обработки пулу потоков, каждый из которых обрабатывает свои ключи.</p>

<p>&mdash; внутреннее шардирование.</p>
    </section>

    <section class="slide">
        <h2>Как шардировать данные</h2>
<p>между серверами?</p>
    </section>

    <section class="slide">
        <h2>Как шардировать данные?</h2>

<p>&mdash; никак :(</p>
    </section>


    <section class="slide">
        <h2>Как реплицировать данные?</h2>

<p>Каждый сервер записывает на диск лог запросов и позволяет реплике считывать и обрабатывать этот лог.</p>
<p>Этот же лог используется для восстановления после сбоя.</p>
<p>Репликация асинхронная <b>eventually inconsistent</b>.</p>
    </section>


    <section class="slide">
        <h2>Как удалять старые данные?</h2>

<p>Три варианта:</p>
<p>&mdash; разбить все данные на корзины по часам и удалять старые корзины;</p>
<p>&mdash; экспоненциальное сглаживание: с некоторой периодичностью делить значения счётчиков в два раза;</p>
<p>&mdash; периодически сбрасываем дамп на диск, перезапускаем сервер и считываем из дампа только актуальные данные.</p>
    </section>


    <section class="slide">
        <h2>Сетевой трафик</h2>

<p>На вход: одно событие &mdash; 50 столбцов UInt64 &mdash; 400 байт<br/>
~ <span style="color: red;">4 GBit/sec</span>.</p>

<p>На выход:
<br/>&mdash; передавать все посчитанные статистики<br/>&mdash; 500 столбцов UInt32 &mdash;
2 КБ ~ <span style="color: red;">20 GBit/sec</span>.
<br/><br/>&mdash; передавать только результат машинно-обученной формулы<br/>&mdash; float &mdash; 4 байта на событие.</p>
    </section>


    <section class="slide">
        <h2>Сетевой трафик</h2>

<p>Но у нас <span style="color: red;">1 GBit</span> сеть :(</p>

<p>Просто будем сжимать данные.</p>

<p><b>LZ4</b> &mdash; слишком слабо.<br/>
<b>QuickLZ</b> &mdash; на 2012 год лучше альтернативы не было,<br/>сейчас не актуально.<br/>
2019 год &mdash; используйте <b>ZSTD</b> или <b>Brotli</b>.</p>
    </section>


    <section class="slide">
        <h2>Критерий роботности</h2>
<p>Как принимать решение о роботности трафика?</p>

<p>Машинно-обученная <b>MatrixNet</b> формула.</p>
<p>Сейчас более совершенная технология доступна<br/>в open-source: <b>CatBoost</b>.</p>

<p><a href="https://github.com/catboost/">https://github.com/catboost/</a></p>
    </section>
    
    <section class="slide">
        <img src="pictures/perf.png" style="width: 120%; margin: 0 -10% 0 -10%;" />
    </section>
    
    <section class="slide">
        <h2>Альтернативы</h2>

<p>&mdash; Redis;
<br/>&mdash; Aerospike;
<br/>&mdash; Couchbase;
<br/>&mdash; Cassandra.</p>

<p>Бонус:</p>

<p>&mdash; YT Dynamic Tables;
<br/>&mdash; RTMR;
<br/>&mdash; YDB.</p>
    </section>


    <section class="slide">
        <h2>Как перестать бояться?</h2>

<p>Хорошо представлять возможности железа.
<br/>Хорошо представлять свойства задачи и её численные характеристики.
<br/>Хорошо представлять внутреннее устройство доступных хранилищ данных.</p>

<p>Самоуверенность и отвага.</p>

<p>Использовать арифметику, чтобы соотнести<br/>свойства задачи с возможностью железа.
<br/><br/>Быть готовым разбираться, если теория не сходится с практикой.</p>
    </section>


    <section class="slide">
        <h2>Далее</h2>

<p>База данных истории посетителей.</p>
<p>Расчёт сессий посетителей.</p>
<p>&mdash; специализированные структуры данных на SSD+RAM.</p>
    </section>


    <section class="slide">
        <h2>?</h2>
    </section>

    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>
</body>
</html>
