<!DOCTYPE html>
<html lang="en">
<head>
    <title>Uncovering the Real-World Performance of AWS Graviton4 with ClickHouse</title>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="shower/themes/yandex/styles/screen-16x9.css">

    <style type="text/css">
         code { display: block; white-space: pre; background-color: #EEE; }
         p.cloud { text-align: center; line-height: 1.6; font-size: 20pt; }
         p.cloud span { color: gray; padding: 0 20px 0 20px; white-space: nowrap; }
         table, tr, td { border: 0; }
         .hilite { background: rgba(255, 255, 255, 80%); padding: 5px; }
    </style>
</head>
<body class="shower list">
    <header class="caption">
        <h1>Uncovering the Real-World Performance<br/>of AWS Graviton4 with ClickHouse</h1>
    </header>
    <section class="slide" id="cover" style="background: url(pictures/title.png); background-size: cover; background-position: center;">
    </section>

<section class="slide">
<h2>What Is ClickHouse?</h2>
<p>An open-source analytic DBMS.</p>
<p>Used everywhere: Microsoft, Spotify, Cloudflare, Lyft, Deutsche Bank,<br/> + thousands companies.</p>
<p>Open-source since 2016, currently the most popular analytic DBMS.</p>
<p>Scalable from a laptop or a server to datacenters.</p>
<p>1,482 contributors and 34,700 stars.</p>
<!--

Open-source with 34,700 stars
Popular in the industry

Speed, low latency, high concurrency, real-time insertion

Bigquery or Snowflake but with no limits
Like Postgres but for analytics

Laptop, server, datacenter

ClickHouse Cloud with
Available in AWS marketplace

-->
</section>

<section class="slide" style="background: url(pictures/history.png); background-size: cover; background-position: center;">
</section>

<section class="slide">
<h2>What Is ClickHouse?</h2>
<p>ClickHouse is like <b>Postgres</b>, but for analytics.</p>

<p>Fast SQL queries with low latency and high concurrency
<br/>with real-time insertion.</p>

<p style="margin-top: 2em;">Available in ClickHouse Cloud, on AWS Marketplace.</p>
</section>

<section class="slide" style="background: url(pictures/cloud.png); background-size: cover; background-position: center;">
</section>

<section class="slide">
<h2>Machines</h2>
<p>AWS has a lot of instance types:
<br/>&mdash; m, c, r, x, z, u; t, a; i, im, d; g, p, f, inf, trn, vt, hpc, mac;</p>
<p>With tweaks:
<br/>&mdash; -d with local disks; -n with faster network; -flex;</p>
<p>Different types and generations of CPU:
<br/>&mdash; i - Intel, a - AMD; up to 7th generation as of May 2024</p>
<p>Different CPU architectures:
<br/>&mdash; x86_64 - Intel and AMD; AArch64 (aka ARM64) - Graviton;</p>
<p>Example: <b>r6idn-24xlarge</b>:
<br/>RAM-optimized (8 GB per vCPU), 6th-generation of Intel CPU, <br/>with local SSD, network optimized, 4*24 vCPU.</p>
</section>


<section class="slide">
<h2>Graviton</h2>
<p><b>AWS Graviton</b> is an Aarch64 CPU, custom built by AWS.</p>
<p>2018 - 1st generation; ... 2024 - 4th generation (currently in preview!)</p>

<p>It is a different architecture, so <span style="color: red;">not all software is going to work</span>.
<br/>Some have to be adapted, compiled, and tested on ARM.</p>
<p>Good news: <b style="color: green;">ClickHouse works!</b> <b>deb</b>, <b>rpm</b>, <b>tgz</b> are available for AArch64</p>
<p>Quick installation autodetects the architecture:
</p>
<p><code>curl https://clickhouse.com/ | sh</code></p>

<!--

a1
c6g, t4g, g4g
c7g

r8g.8xlarge
r8g.24xlarge

clickhouse-cloud :) SELECT sum(cityHash64(*)) FROM build_time_trace

SELECT sum(cityHash64(*))
FROM build_time_trace

Query id: 419da4ff-1430-4bbf-86fb-8be60a77c6a1

   â”Œâ”€sum(cityHash64(pull_request_number, commit_sha, check_start_time, check_name, instance_type, instance_id, file, library, date, time, pid, tid, ph, ts, dur, cat, name, detail, count, avgMs, args_name, is_total))â”€â”
1. â”‚                                                                                                                                                                                               18424954377991503633 â”‚ -- 18.42 quintillion
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1 row in set. Elapsed: 3745.202 sec. Processed 1.07 trillion rows, 374.14 TB (285.45 million rows/s., 99.90 GB/s.)

-->
</section>

<section class="slide">
<h2>Let's Play!</h2>
<p>Step 1: run a benchmark on every generation.</p>
<p>ClickBench: <a href="https://benchmark.clickhouse.com/hardware">https://benchmark.clickhouse.com/hardware</a></p>
<p>&mdash; fully automated benchmark, runs on all instance types.
<br/>&mdash; attempts to mimic a clickstream analytics workload;</p>
<p>Btw, you can run it by yourself and submit results.</p>
<p style="margin-top: 2em;"><b>Results (demo):</b> <a href="https://pastila.nl/?000b1ba6/b62151980ba3951808f7e5ee9ed26c97.html">https://pastila.nl/?000b1ba6/b62151980ba3951808f7e5ee9ed26c97.html</a></p>
</section>

<section class="slide">
<h2>How To Decide?</h2>
<p><b>Throughput on a single query:</b>
<br/>&mdash; how quickly a massively-parallel query runs, e.g. 1 second vs 1.5 seconds;
<br/>&mdash; depends on the number of CPU; aggregate performance; and mem bw;
<br/>&emsp; and on the software optimization for a particular instruction set;
</p>

<p><b>Latency on short queries:</b>
<br/>&mdash; how quickly a small query runs, e.g. 25 ms vs 50 ms.
<br/>&mdash; depends on the speed of a single CPU core;
</p>

<p><b>Total load capacity:</b>
<br/>&mdash; how many concurrent users and QPS can we sustain.
<br/>&mdash; depends on the aggregate CPU performance and memory bw;
</p>
</section>

<section class="slide">
<h2>How To Decide?</h2>

<p><b>Availability of the instances:</b>
<br/>&mdash; in particular regions; in particular configurations.
<br/>&mdash; ask your AWS architect.
</p>

<p><b>Software compatibility:</b>
<br/>&mdash; and how well it is tested on this architecture.
</p>

<p><b>Cost/performance:</b>
<br/>&mdash; this also depends on what performance metric is in comparison.
</p>

<!--

a1.4xlarge:  $0.4080
c6g.4xlarge: $0.5440   +33%    avg 3 times faster
c7g.4xlarge: $0.5800   +6.6%   avg 30% faster

r6g.8xlarge: $1.6128
r7g.8xlarge: $1.7136   +6.25%  avg 30% faster
r8g.8xlarge: preview           avg 30% faster

r7i.8xlarge: $2.016

r6g.16xlarge: $3.2256
r7g.16xlarge: $3.4272  +6.25%
r8g.16xlarge: preview

-->
</section>

<section class="slide">
<h2>Let's Play!</h2>
<p>Step 1: estimate total capacity.</p>
<p>By running all ClickBench's queries in parallel:</p>
<p><code>clickhouse-benchmark -c32 -i1000 &lt; queries.sql</code></p>
<table>
<tr><th>machine</th><th>QPS</th><th>cost</th></tr>
<tr><td>r7i.8xlarge</td><td>2.800</td><td>$2.0160</td></tr>
<tr><td>r7g.8xlarge</td><td>3.500 (+25%)</td><td>$1.7136 (-15%)</td></tr>
<tr><td>r8g.8xlarge</td><td>4.595 (+64%)</td><td style="color: gray">preview</td></tr>
</table>
</section>


<section class="slide">
<h2>Should we use Graviton today?</h2>

<p>Summary compared to contemporary Intel/AMD machines:</p>

<p>Graviton 1 (2018):<br/>&mdash; low powerful machines, not comparable in performance.</p>
<p>Graviton 2 (2020):<br/>&mdash; comparable throughput, but single-core performance is lower.</p>
<p>Graviton 3 (2022):<br/>&mdash; better throughput and comparable single-core performance.</p>
<p>Graviton 4 (2024):<br/>&mdash; even better throughput, lower latency, and more cores ðŸ˜‹.</p>
</section>

<section class="slide">
<h2>Can we use Graviton today?</h2>

<p>In ClickHouse Cloud.</p>
<p><b style="color: green;">It looks obvious</b>: we can get more power for lower price!</p>
<p>But it is <b>not so obvious</b>...</p>

<p><b>Availability of disk instances</b>
<br/>ClickHouse Cloud uses S3 and local SSDs for cache. But Graviton 3 instances with local SSDs started to be available in required regions only recently.</p>

<p><b>Live migration</b>
<br/>A cluster should be able to run in a hybrid mode &mdash; some replicas x86_64, some AArch64.
</p>
</section>

<section class="slide">
<h2>Can we use Graviton today?</h2>

<p><b>Orchestration and infrastructure</b>
<br/>All components have to be ported to AArch64 as well.
</p>

<p><b>Full continuous integration</b> with all test suites
<br/>had to be enabled on Graviton instance types.</p>

<p><b>Feature parity</b>
<br/>Every existing feature should work on AArch64, even rarely used ones.
<br/>Especially our own debugging and introspection capabilities.
</p>

<p><b>Pricing and performance consistency</b>
<br/>We cannot randomly give 2x powerful machines in a subset of regions,
<br/>as it could lead into surprises for customers.
</p>
</section>

<section class="slide">
<h2>Can we use Graviton today?</h2>

<p>We have to do it! The advantages are overwhelming.</p>

<p>So we prepared everything and migrated our staging environment to Graviton :)</p>

<p><b>Feature parity</b>
<br/>Every existing feature should work on AArch64, even rarely used ones.
<br/>Especially our own debugging and introspection capabilities.
</p>

<p><b>Pricing and performance consistency</b>
<br/>We cannot randomly give 2x powerful machines in a subset of cases,
<br/>as it could lead into surprises for customers.
</p>
</section>




<section class="slide" style="background: url(pictures/flightradar24.png); background-size: cover; background-position: center;">
</section>

<section class="slide">
<h2>I want it in ClickHouse!</h2>
<p>There are many ADS-B data exchanges:</p>
<p style="font-family: monospace;">&mdash; adsb.fi
<br/>&mdash; adsb.one
<br/>&mdash; adsb.lol
<br/>&mdash; adsbhub.org
<br/>&mdash; airplanes.live
<br/>&mdash; openflights.org
<br/>&mdash; flightaware.com
<br/>&mdash; adsbexchange.com
<br/>&mdash; flightradar24.com
<br/>&mdash; opensky-network.org</p>
</section>

<section class="slide" style="background: url(pictures/adsblol.png); background-size: cover; background-position: center;">
</section>

<section class="slide">
<h2>Which data source to use?</h2>
<p><b style="color: green;">adsb.lol</b> &mdash; ODbL, direct batch data downloads, ~1 TB/year, from Feb 2023.</p>
<p><b style="color: #444400;">adsbexchange.com</b> &mdash; sample data for 1st day of each month, better coverage.</p>
<p><b style="color: darkgreen;">airplanes.live</b> &mdash; the author provided the archive on request,<br/>for non-commercial usage with restrictions (no redistribution).</p>
</section>

<section class="slide" style="background: url(pictures/adsblol_releases.png); background-size: cover; background-position: center;">
</section>

<section class="slide">
<h2>The Easy Part</h2>
<p>Download all the data.</p>
<p>Insert into ClickHouse.</p>
</section>

<section class="slide">
<h2>The Easy Part</h2>
<p>The data is just a bunch of JSON files, produced by the <b>readsb</b> tool.</p>

<code style="font-size: 14pt; line-height: 1.25; white-space: pre-wrap; overflow-x: auto; overflow-y: scroll; height: 18em;">{<span style="color: brown;">"icao":"020100",
"r":"CN-COH",
"t":"AT76",               <span style="color: gray;">&lt;-- metadata</span>
"dbFlags":0,                                 <span style="color: gray;">traces</span>
"desc":"ATR-72-600",                         <span style="color: gray;">  |</span>
"timestamp": 1680307200.000,</span>                 <span style="color: gray;">  v</span>
"trace":[
<span style="color: darkblue;">[44993.52,36.589873,-8.205326,20000,200.9,340.2,1,0,null,"adsb_icao",21050,32,175,0.7],
[45022.97,36.615921,-8.216915,20000,200.9,340.2,1,0,null,"adsb_icao",21050,null,null,null],
[45063.81,36.651352,-8.232708,20000,200.9,340.2,1,0,{"type":"adsb_icao","flight":"RAM980E ","alt_geom":21050,"ias":175,"tas":242,"mach":0.384,"wd":304,"ws":50,"track":340.21,"roll":0.00,"mag_heading":334.34,"true_heading":333.25,"baro_rate":0,"geom_rate":32,"squawk":"7737","category":"A2","nav_qnh":1013.6,"nav_altitude_mcp":20000,"nic":8,"rc":186,"version":2,"nic_baro":1,"nac_p":9,"nac_v":2,"sil":3,"sil_type":"perhour","alert":0,"spi":0},"adsb_icao",21050,32,175,0.0],
[45081.72,36.667191,-8.239746,20000,200.9,340.2,1,0,null,"adsb_icao",21050,32,175,0.0],
[45094.87,36.678589,-8.244839,20000,199.6,340.4,0,64,null,"adsb_icao",21050,64,173,0.0],
[45120.17,36.700993,-8.254765,20000,199.9,340.1,1,0,null,"adsb_icao",21050,0,173,0.0],</span>
</code>
</section>

<section class="slide">
<h2>The Easy Part</h2>
<p>1. Split each JSON into two: metadata and traces.</p>
<p>2. Join them together into a flat table.</p>
<p>3. Insert into the destination ClickHouse server.</p>
</section>

<section class="slide">
<h2>The Easy Part</h2>
<p>Join two JSON files and cleanup the data:</p>
<p><code style="font-size: 14pt; line-height: 1.25;">clickhouse-local --query "
  INSERT INTO FUNCTION remoteSecure('...aws.clickhouse.cloud',
    default.planes_mercator, 'default', '')
  SELECT
    CAST(timestamp + time_offset AS DateTime64(3)) AS time,
    time::Date AS date,
    icao, r, t, dbFlags, noRegData, ownOp, year, desc,
    lat, lon,
    toInt32OrZero(altitude),
    ...
  FROM
    file('${TMPFILE}.data.jsonl', JSONCompactEachRow) AS d,
    file('${TMPFILE}.meta.jsonl', JSONEachRow) AS m
"</code></p>
</section>


<section class="slide">
<h2>A Table</h2>
<code style="font-size: 10pt; line-height: 1.25; white-space: pre-wrap; overflow-x: auto; overflow-y: scroll; height: 33em; margin-top: -3em; margin-left: -2em; margin-right: -2em;">CREATE TABLE planes_mercator
(
    mercator_x UInt32 MATERIALIZED 0xFFFFFFFF * ((lon + 180) / 360),
    mercator_y UInt32 MATERIALIZED 0xFFFFFFFF * (1/2 - log(tan((lat + 90) / 360 * pi())) / 2 / pi()),

    INDEX idx_x (mercator_x) TYPE minmax,
    INDEX idx_y (mercator_y) TYPE minmax,

    time DateTime64(3),
    date Date,
    icao String,
    r String,
    t LowCardinality(String),
    dbFlags Int32,
    noRegData Bool,
    ownOp LowCardinality(String),
    year UInt16,
    desc LowCardinality(String),
    lat Float64,
    lon Float64,
    altitude Int32,
    ground_speed Float32,
    track_degrees Float32,
    flags UInt32,
    vertical_rate Int32,
    aircraft_alert Int64,
    aircraft_alt_geom Int64,
    aircraft_gva Int64,
    aircraft_nac_p Int64,
    aircraft_nac_v Int64,
    aircraft_nic Int64,
    aircraft_nic_baro Int64,
    aircraft_rc Int64,
    aircraft_sda Int64,
    aircraft_sil Int64,
    aircraft_sil_type LowCardinality(String),
    aircraft_spi Int64,
    aircraft_track Float64,
    aircraft_type LowCardinality(String),
    aircraft_version Int64,
    aircraft_category Enum8(
        'A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7',
        'B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7',
        'C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',
        'D0', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7',
        ''),
    aircraft_emergency Enum8('', 'none', 'general', 'downed', 'lifeguard', 'minfuel', 'nordo', 'unlawful', 'reserved'),
    aircraft_flight LowCardinality(String),
    aircraft_squawk String,
    aircraft_baro_rate Int64,
    aircraft_nav_altitude_fms Int64,
    aircraft_nav_altitude_mcp Int64,
    aircraft_nav_modes Array(Enum8('althold', 'approach', 'autopilot', 'lnav', 'tcas', 'vnav')),
    aircraft_nav_qnh Float64,
    aircraft_geom_rate Int64,
    aircraft_ias Int64,
    aircraft_mach Float64,
    aircraft_mag_heading Float64,
    aircraft_oat Int64,
    aircraft_roll Float64,
    aircraft_tas Int64,
    aircraft_tat Int64,
    aircraft_true_heading Float64,
    aircraft_wd Int64,
    aircraft_ws Int64,
    aircraft_track_rate Float64,
    aircraft_nav_heading Float64,
    source LowCardinality(String),
    geometric_altitude Int32,
    geometric_vertical_rate Int32,
    indicated_airspeed Int32,
    roll_angle Float32,

    data_source Enum8('', 'adsb.lol', 'adsbexchange', 'airplanes.live')
) ENGINE = MergeTree ORDER BY (mortonEncode(mercator_x, mercator_y), time);
</code>
</section>


<section class="slide">
<h2>I have a table, now what?</h2>

<p>After a day, the table contains 50 billion records, around 1.6 TB.</p>
<p>What to do with this data?</p>
<p>&mdash; something beautiful!</p>

<p style="margin-top: 2em; color: green;">Visualize it on the fly in the browser.</p>
<p style="color: green;">Aggregate and generate reports.</p>
</section>

<section class="slide">
<h2>Demo</h2>
<p><a href="https://adsb.exposed/">https://adsb.exposed/</a></p>
</section>

<section class="slide">
<h2>How Is It Possible?</h2>
</section>

<section class="slide">
<h2>REST API</h2>
<p>ClickHouse has HTTP API included.</p>
<p><code style="font-size: 14pt; line-height: 1.5;">const url = `${host}/?user=website&amp;default_format=JSON&amp;param_x=${x}`;
const response = await fetch(host, { method: 'POST', body: sql });
const data = await response.json();
</code></p>
<p>You can query it directly from the web page.</p>
<p style="margin-top: 2em;">Advanced usage? &mdash; use the TypeScript driver.</p>
<p>Any other language? &mdash; there are drivers for all of them.</p>
</section>

<section class="slide">
<h2>Parameterized Queries</h2>
<p>Type-safe parameterized queries:</p>
<p><code style="font-size: 14pt; line-height: 1.5;">WITH
    tile_size * <b style="color: green;">{x:UInt16}</b> AS tile_x_begin,
    tile_size * <b style="color: green;">{y:UInt16}</b> AS tile_y_begin,
...
SELECT round(red)::UInt8, round(green)::UInt8, round(blue)::UInt8
FROM <b style="color: green;">{table:Identifier}</b>
</code></p>
<p>Bonus: parameterized views.</p>
<p><code style="font-size: 14pt; line-height: 1.5;">CREATE VIEW example AS SELECT ...;
SELECT * FROM <b style="color: green;">example(x = 123, y = 456)</b>;</b>
</code></p>
</section>

<section class="slide">
<h2>Materialized Views</h2>

<p><code style="font-size: 14pt; line-height: 1.5;">CREATE TABLE planes_mercator_sample10 AS planes_mercator;

CREATE TABLE planes_mercator_sample100 AS planes_mercator;

CREATE MATERIALIZED VIEW view_sample10 TO planes_mercator_sample10
AS SELECT * FROM planes_mercator WHERE rand() % 10 = 0;

CREATE MATERIALIZED VIEW view_sample100 TO planes_mercator_sample100
AS SELECT * FROM planes_mercator WHERE rand() % 100 = 0;
</code></p>

<p>Can be used for incremental (continuous) data transformations on inserts,<br/>
such as aggregation, filtering, and indexing data in different ways.</p>
</section>

<section class="slide">
<h2>Role-Based Access Control</h2>

<p><code style="font-size: 14pt; line-height: 1.5;">CREATE USER website IDENTIFIED WITH sha256_hash BY '...'
SETTINGS
    add_http_cors_header = 1,
    max_result_rows = 1048576,
    ...
    readonly = 1;

GRANT SELECT ON default.planes_mercator TO website;
GRANT SELECT ON default.planes_mercator_sample10 TO website;
GRANT SELECT ON default.planes_mercator_sample100 TO website;

CREATE USER website_progress IDENTIFIED WITH sha256_hash BY ...;
GRANT SELECT ON system.processes TO website_progress;
GRANT REMOTE ON *.* TO website_progress;
</code></p>
</section>

<section class="slide">
<h2>Quotas and Query Complexity Limits</h2>
<p><code style="font-size: 14pt; line-height: 1.5;">CREATE QUOTA website
KEYED BY ip_address
FOR RANDOMIZED INTERVAL 1 MINUTE
  MAX query_selects = 1000, read_rows = 100_000_000_000,
FOR RANDOMIZED INTERVAL 1 HOUR
  MAX query_selects = 10000, read_rows = 1_000_000_000_000,
FOR RANDOMIZED INTERVAL 1 DAY
  MAX query_selects = 50000, read_rows = 5_000_000_000_000
TO website;

CREATE USER ... SETTINGS
    max_result_rows = 1048576,
    enable_http_compression = 1,
    max_execution_time = 180;
</code></p>
</section>

<section class="slide">
<h2>Indices On Expressions</h2>
<p><code style="font-size: 12pt; line-height: 1.5;">CREATE TABLE planes_mercator
(
    mercator_x UInt32 <b style="color: green;">MATERIALIZED</b> 0xFFFFFFFF * ((lon + 180) / 360),
    mercator_y UInt32 <b style="color: green;">MATERIALIZED</b>
        0xFFFFFFFF * (1/2 - log(tan((lat + 90) / 360 * pi())) / 2 / pi()),

    INDEX idx_x (mercator_x) TYPE minmax,
    INDEX idx_y (mercator_y) TYPE minmax,

    time DateTime64(3),
    lat Float64,
    lon Float64,
    ...
) ENGINE = MergeTree
ORDER BY (<b style="color: green;">mortonEncode(mercator_x, mercator_y)</b>, time);
</code></p>
</section>

<section class="slide">
<h2>Modern, Friendly SQL</h2>
<p><code style="font-size: 12pt; line-height: 1.25; margin-top: -1em;">WITH <span style="color: gray;">-- can be used for CTE and for scalar aliases</span>
    tile_size * {x:UInt16} AS tile_x_begin,
    tile_size * {y:UInt16} AS tile_y_begin,
    <span style="color: gray;">...</span>
    mercator_x >= tile_x_begin AND mercator_x &lt; tile_x_end
    AND mercator_y >= tile_y_begin AND mercator_y &lt; tile_y_end AS in_tile,
    <span style="color: gray;">...</span>
    bitShiftRight(mercator_x - tile_x_begin, 32 - 10 - {z:UInt8}) AS x,
    bitShiftRight(mercator_y - tile_y_begin, 32 - 10 - {z:UInt8}) AS y,
    <span style="color: gray;">...</span>
    <span style="color: gray;">-- aliases can refernce each other in expressions;</span>
    y * 1024 + x AS pos,
    <span style="color: gray;">...</span>
SELECT round(red)::UInt8, round(green)::UInt8, round(blue)::UInt8
FROM {table:Identifier} <span style="color: gray;">-- query parameters</span>
WHERE in_tile <span style="color: gray;">-- aliases in any place of a query</span>
GROUP BY pos
ORDER BY pos <b style="color: green;">WITH FILL FROM 0 TO 1024*1024</span></b> <span style="color: gray;">-- gaps filling;</span>
</code></p>
</section>

<section class="slide">
<h2>Input/Output Formats</h2>
<p><b>TSV</b>, <b>CSV</b>, <b>CustomSeparated</b>... &mdash; text formats;</p>
<p><b>RowBinary</b> &mdash; compact, raw bitmap (we use it for pictures);</p>
<p><b>JSON</b>, <b>JSONLines</b>, <b>JSONCompact</b>... &mdash; good for web UIs;</p>
<p><b>Parquet</b>, <b>ORC</b>, <b>Arrow</b>, <b>Native</b>... &mdash; column-oriented (for data lakes);</p>
<p><b>Protobuf</b>, <b>Avro</b>, <b>MsgPack</b>... &mdash; import/export (for Kafka and similar);</p>
<p style="color: green;">... every format you might need is already supported by ClickHouse!</p>
</section>

<section class="slide">
<h2>Compression Out Of The Box</h2>
<p>Data inside ClickHouse is compressed<br/>in a column-oriented format (MergeTree);</p>
<p>Compression for external data is automatically recognized<br/>(gz, lz4, zstd, br, snappy, bz2, xz; zip, 7z, tar.*);</p>
<p>Compression over network is supported as well<br/>(Accept-Encoding, Content-Encoding in the HTTP interface);</p>
</section>

<section class="slide">
<h2>Infinite Storage</h2>
<p>ClickHouse supports:</p>
<p>&mdash; local storage;</p>
<p>&mdash; object storage (AWS S3, GCS, and Azure);</p>
<p>&mdash; hybrid storage (tiering and/or caching);</p>
<p>&mdash; external tables (data lakes and querying other databases);</p>
<p style="color: gray; margin-top: 2em;">* ClickHouse Cloud has unlimited storage.</p>
</section>

<section class="slide">
<h2>Parallel And Distributed Queries</h2>
<p>Add CPU and/or machines, and your queries run faster:</p>
<p>&mdash; queries parallelize across all CPU cores on the machine<br/>&emsp; (you can also limit it);</p>
<p>&mdash; queries parallelize using <b>shards</b> or <b>replicas</b>;</p>
</section>

<section class="slide">
<h2>Query Result Cache</h2>

<p><code style="line-height: 1.5">$ cat /etc/clickhouse-server/config.d/query_cache.yaml
query_result_cache:
    size: 1073741824
    max_entries: 1024
    max_entry_size: 104857600
    max_entry_records: 30000000
</code></p>
<p><code style="line-height: 1.5">SET use_query_cache = 1;</code></p>
</section>

<section class="slide">
<h2>Query Result Cache</h2>

<p>Allows to control on a per-query basis:</p>
<p style="line-height: 1.25;">&mdash; min query runs to cache the result;<br/>
&mdash; min query runtime to cache the result;<br/>
&mdash; max result size to put into cache;<br/>
&mdash; max staleness to use the cached entry;<br/>
&mdash; passive usage of the existing entries in cache;<br/>
&mdash; caching of queries with non-deterministic functions;<br/>
&mdash; sharing the cache between users;</p>
</section>

<section class="slide">
<h2>Local And Server Modes</h2>
<p style="margin-top: -1em;">ClickHouse can work <b>as a server</b> (clickhouse-server)
<br/>or <b>as a tool</b> without installation (clickhouse-local).</p>

<p><b style="color: green;">clickhouse-local</b>
<br/>&mdash; a small tool for data analytics on local and remote datasets.</p>

<p><b>All possible data formats:</b>
<br/>&mdash; text: CSV, TSV, JSON, Values, MySQLDump, Regexp...
<br/>&mdash; binary: Parquet, Arrow, ORC, Avro, BSON, Protobuf, MsgPack...
<br/>&mdash; schemaful and schemaless;
</p>

<p><b>External data:</b>
<br/>&mdash; remote databases: MySQL, PostgreSQL, MongoDB, ODBC, JDBC...
<br/>&mdash; object storages: S3, HDFS, Azure...
<br/>&mdash; external tables: Hudi, Delta Lake...
<br/>&mdash; from URL and local files; from SQLite.
</p>
</section>

<section class="slide">
<h2>Preprocessing the Data</h2>
<p style="margin-top: -1em;">With <b style="color: green;">clickhouse-local</b>
<br/>&mdash; a small tool for data analytics on local and remote datasets.</p>
<p>Similar tools:<br/><span style="color: gray;">textql, octosql, dsq, duckdb, glaredb, trdsql, q, datafusion-cli, spyql</span>.</p>

<p>Install it:</p>
<p><code>curl https://clickhouse.com/ | sh

./clickhouse local</code></p>
</section>

<section class="slide">
<h2>What Else?</h2>
<p>ClickHouse is the best DBMS for analytic applications:</p>
<p>&mdash; Fast, scalable, and resource efficient;</p>
<p>&mdash; Easy to use and pleasant to work with;</p>
<p>&mdash; Robust and reliable;</p>
<p>&mdash; Batteries included.</p>
<p style="margin-top: 2em;">Friends tell friends to use ClickHouse!</p>
</section>

<section class="slide" style="background: url(pictures/Copenhagen_airport_from_air.jpg); background-size: cover; background-position: center;">
<a href="https://en.wikipedia.org/wiki/Copenhagen_Airport#/media/File:Copenhagen_airport_from_air.jpg" style="position: absolute; right: 1em; bottom: 1em; color: gray; font-size: 8pt;">kallerna, 2019, CC BY-SA 4.0</a>
<h2><span class="hilite">Q&amp;A</a></h2>
</section>


    <div class="progress"></div>
    <script src="shower/shower.min.js"></script>

    <!--Video plugin-->
    <link rel="stylesheet" href="shower/shower-video.css">
    <script src="shower/shower-video.js"></script>
    <!--/Video plugin-->
</body>
</html>

